---
title: "Defer Sender Algorithm Customization to Post-C++26"
document: D3826R0
date: today
audience:
  - "SG1 Concurrency and Parallelism Working Group"
  - "LEWG Library Evolution Working Group"
  - "LWG Library Working Group"
author:
  - name: Eric Niebler
    email: <eric.niebler@gmail.com>
toc: true
---


# Background

In the current Working Draft, [exec]{.sref} has sender algorithms that are customizable.
While the sender/receiver concepts and the algorithms themselves have been stable for
several years now, the customization mechanism has seen a fair bit of recent churn.
[@P3718R0] is the latest effort to shore up the mechanism. Unfortunately, there are gaps
in its proposed resolution. This paper details those gaps.

The problems are fixable although the fixes are non-trivial. The time for elaborate fixes
has passed. This paper proposes to remove the ability to customize sender algorithms for
C++26. A future paper will propose to add the feature back post-'26.

The author feels that postponing the feature will be less disruptive and safer than trying
to patch it at the last minute. Most common usages of sender/receiver will not be
affected.

# The problem with P3718

[@P3718R0] identifies real problems with the status quo of sender algorithm customization.
It proposes using information from the sender about where it will *complete* during
"early" customization, which happens when a sender algorithm constructs and returns a
sender; and it proposes using information from the receiver about where the operation will
*start* during "late" customization, when the sender and the receiver are connected.

The problem with this separation of responsibilities is that many senders do not know
where they will complete until they know where they will be started. A simple example is
the `just()`{.cpp} sender; it completes inline wherever it is started. And the information
about where a sender will start is not known during early customization, when the sender
is being asked for this information.

For the expression `then(sndr, fn)`{.cpp} for example, if the `then`{.cpp} CPO asks
`sndr`{.cpp} where it will complete, `sndr`{.cpp} might not be able to answer, in which
case no "early" customization is performed. And during "late" (`connect`-time)
customization, only the receiver's information about where the operation will start is
used to find a customization. Presumably an algorithm like `then(sndr, fn)`{.cpp} would
want to dispatch based on where the function `fn`{.cpp} will execute, but for some
expressions that information cannot be determined with the API proposed in P3718.

An illustrative example is:

> ```cpp
> namespace ex = std::execution;
> auto sndr = ex::starts_on(gpu, ex::just()) | ex::then(fn);
> std::this_thread::sync_wait(std::move(sndr));
> ```

... where `gpu`{.cpp} is a scheduler that runs work (unsurprisingly) on a GPU.

`fn`{.cpp} will execute on the GPU, so a GPU implementation of `then`{.cpp} should be used. By the
proposed resolution of P3718, algorithm customization proceeds as follows:

* During early customization, when `starts_on(gpu, just()) | then(fn)`{.cpp} is executing,
  the `then`{.cpp} CPO asks the `starts_on(gpu, just())`{.cpp} sender where it will complete
  as if by:

  > ```cpp
  > auto&& @_`tmp1`_@ = ex::starts_on(gpu, ex::just());
  > auto @_`dom1`_@ = ex::get_domain(ex::get_env(@_`tmp1`_@));
  > ```

* The `starts_on`{.cpp} sender will in turn ask the `just()`{.cpp} sender, as if by:

  > ```cpp
  > auto&& @_`tmp2`_@ = ex::just();
  > auto @_`dom2`_@ = ex::get_domain(ex::get_env(@_`tmp2`_@));
  > ```

  As discussed, the `just()`{.cpp} sender doesn't know where it will complete until
  it knows where it will be started, but that information is not yet available. As a
  result, _`dom2`_ ends up as `default_domain`{.cpp}, which is then reported as the domain
  for the `starts_on`{.cpp} sender. That's incorrect. The `starts_on`{.cpp} sender will
  complete on the GPU.

* The `then`{.cpp} CPO uses `default_domain`{.cpp} to find an implementation of the
  `then`{.cpp} algorithm, which will find the default implementation. As a result, the
  `then`{.cpp} CPO returns an ordinary `then`{.cpp} sender.

* When that `then`{.cpp} sender is connected to `sync_wait`{.cpp}'s receiver, late
  customization happens. `connect`{.cpp} asks `sync_wait`{.cpp}'s receiver where the
  `then`{.cpp} sender will be started. It does that with
  `get_domain(get_env(rcvr))`{.cpp}. `sync_wait`{.cpp} starts operations on the current
  thread, so the `get_domain`{.cpp} query will return `default_domain`{.cpp}. As with
  early customization, late customization will also not find a GPU implementation.

The end result of all of this is that a default (which is effectively a CPU) implementation will be used to evaluate
the `then`{.cpp} algorithm on the GPU. That is a bad state of affairs.

# Solutions considered

OK, so there is a problem. What do we do? There are a number of different options.

## Remove all of the C++26 `std::execution` additions

Although the safest option, I hope most agree that such a drastic step is not warranted by
this issue. Pulling the `sender` abstraction and everything that depends on it would result
in the removal of:

- The sender/receiver-related concepts and customization points, without which
  the ecosystem will have no shared async abstraction, and which will set back the
  adoption of structured concurrency three years.

- The sender algorithms, which capture common async patterns and make them reusable,

- `execution::counting_scope` and `execution::simple_counting_scope`, and related
  features for incremental adoption of structured concurrency,

- `execution::parallel_scheduler` and all of its related APIs, and

- `execution::task` and `execution::task_scheduler` (C++26 will _still_
  not have a standard coroutine task type <small><em>&lt;heavy sigh&gt;</em></small>).

This option should only be considered if all the other options are determined to have
unacceptable risk.

## Remove all of the customizable sender algorithms

This option would keep all of the above library components with the exception of the
customizable sender algorithms:

- `then`, `upon_error`, `upon_stopped`
- `let_value`, `let_error`, `let_stopped`
- `bulk`, `bulk_chunked`, `bulk_unchunked`
- `starts_on`, `continues_on`, `on`
- `when_all`, `when_all_with_variant`
- `stopped_as_optional`, `stopped_as_error`
- `into_variant`
- `sync_wait`
- `affine_on`

This would leave users with no easy standard way to start work on a given execution
context, or transition to another execution context, or to execute work in parallel,
or to wait for work to finish.

In fact, without the `bulk` algorithms, we leave no way for the `parallel_scheduler`
to execute work in parallel!

While still delivering a standard async abstraction with minimal risk, the loss of the
algorithms would make it _just_ an abstraction. Like coroutines, adoption of senders as an
async _lingua franca_ will be hampered by lack of standard library support.


## Remove sender algorithm customization

This is the option this paper proposes. We ship everything currently in the Working Draft
but remove the ability to customize the algorithms. This gives us a free hand to design a
better customization mechanism for C++29 -- provided we have high confidence that those
new customization hooks can be added without break existing behavior.

A fair question is: how can we have such certainty when we do not know what the
customization hooks are yet?

To answer that question for myself, I implemented new customization hooks
[here](https://github.com/NVIDIA/cccl/pull/5793) that address the known issues. Using that
design (described in [](#appendix-a-the-planned-fix)) as a polestar, this paper proposes
wording to remove customization in such a way that will let us add it back later without
breakage.

My experience implementing the solution gives me confidence that we can introduce
that solution or one like it later without compatibility problems.

## Ship everything as-is and fix algorithm customization in a DR

This option is not as reckless as it sounds. I describe the shape of a possible fix in
[](#appendix-a-the-planned-fix). It would not be the first time the Committee
shipped a standard with known defects, and the DR process exists for just this purpose.

What gives me pause, however, is the fact that I have "fixed" this problem before
only to find that my fix is broken, and not just once!

I have implemented my planned fix, and it _seems_ to work, but it has not seen any
real-world usage. In short, my confidence is not high enough to endorse this
solution.

Should someone with sufficient interest come and vet my solution, I might change my mind.
Shipping it as-is is certainly the least amount of work for everyone involved.


# Implications of removal

Removing algorithm customization is fairly straightforward in most regards, but there
are a few parts of `std::execution` that need special care.

## The parallel scheduler

The `parallel_scheduler` goes to great lengths to ensure that the `bulk` family of
algorithms -- `bulk`, `bulk_chunked`, and `bulk_unchunked` -- are executed in parallel
when the users requests it and when the underlying execution context supports it.

To that end, the `parallel_scheduler` "provides a customized implementation" of the
`bulk_chunked` and `bulk_unchunked` algorithms, but nothing is said about how those custom
implementations are found or under what circumstances users can be assured that the
`parallel_scheduler` will use them. Arguably, this is under-specified in the current
Working Draft and should be addressed whether this paper is accepted or not.

*We have to give users a guarantee that if _X_, _Y_, and _Z_ conditions are met,
`bulk[_[un]chunked]`{.cpp}* <u>will</u> *be run in parallel with absolute certainty.*

One solution is to say that the `bulk` algorithms are guaranteed to execute in parallel
when the immediate predecessor of the `bulk` operation is known to complete on the
`parallel_scheduler`. In a sender expression such as the following:

> ```cpp
> sndr | std::execution::bulk(std::par, 1024, fn)
> ```

If `sndr`'s attributes advertizes a completion scheduler of type `parallel_scheduler`,
then we can guarantee that the `bulk` operation will execute in parallel. Implementations
can choose to parallelize `bulk` under other circumstances, but we require this one.

The implication of offering this guarantee is that we must preserve the guarantee going
forward. Any new customization mechanism we might add must _never_ result in parallel
execution becoming serialized.

The reverse is not necessarily true though. I maintain that a future change that
parallelizes a `bulk` algorithm that formerly executed serially on the `parallel_scheduler`
is an acceptable change of behavior.

If SG1 or LEWG disagrees, there are ways to avoid even this behavior change.

## The task scheduler

Library issue [#4336](https://cplusplus.github.io/LWG/issue4336) describes the
poor interaction between `task_scheduler`, a type-erased scheduler, and the `bulk`
family of algorithms; namely, that the `task_scheduler` always executes `bulk`
in serial, even when it is wrapping a `parallel_scheduler`.

This is not a problem caused by the customization mechanism, but it is something
that can be addressed as part of the customization removal process.

When we address that issue, we must avoid the `parallel_scheduler` pitfall by
under-specifying the interaction with `bulk`. As with `parallel_scheduler`, users must
have a guarantee about the conditions under which `bulk` is accelerated on a
`task_scheduler`.

Fortunately, the `parallel_scheduler` has already given us a way to punch the
`bulk_chunked` and `bulk_unchunked` algorithms through a type-erased API boundary:
`parallel_scheduler_backend` ([exec.sysctxrepl.psb]{.sref}). By specifying
the behavior of `task_scheduler` in terms of `parallel_scheduler_backend` and
`bulk_item_receiver_proxy`, we can give `task_scheduler` the ability to parallelize
`bulk` without having to invent a new mechanism.


## The `bulk` algorithms

Few users will ever have a need to customize an algorithm like `then` or `let_value`.
The `bulk` algorithms are a different story. Anybody with a custom thread pool will
benefit from a custom `bulk` implementation that can run in parallel on the thread
pool. The loss of algorithm customization is particularly painful in this area. This
section explores some options to address these concerns and makes a recommendation.

### Option 1: Remove `bulk`, `bulk_chunked`, and `bulk_unchunked`

This option cuts the Gordian knot, but comes at a high cost. The `parallel_scheduler`
can hardly be called "parallel" if it does not offer a way to execute work in
parallel, so cutting the `bulk` algorithms probably means cutting `parallel_scheduler`
also.

### Option 2: Magical parallel execution

In this option, we keep the `bulk` algorithms and the `parallel_scheduler`, and we say
that the `bulk` algorithms are executed in parallel on the `parallel_scheduler` (and on a
`task_scheduler` that wraps a `parallel_scheduler`), but we leave the mechanism
unspecified.

This option is essentially the _status quo_, except that as discussed in [](#the-parallel-scheduler),
this aspect of the `parallel_scheduler` is currently under-specified. The referenced section proposes a path forward.

A variant of this option is to specify an exposition-only mechanism whereby `bulk`
gets parallelized.

This option makes `parallel_scheduler` and `task_scheduler` "magic" with respect to the
`bulk` algorithms. End users would have no standard mechanism to parallelize `bulk` on
their own third-party thread pools in C++26.

This is the approach taken by the [](#proposed-wording) below.

### Option 3: A normative mechanism for the `bulk*` algorithms only

In this option, we reintroduce algorithm customization with a special-purpose API just for
the `bulk` algorithms. For example, a scheduler might have an optional
`sch.bulk_transform(sndr, env)` that turns a serial `bulk*` sender into one that
executes in parallel on scheduler `sch`. Whenever a `bulk*` sender is passed to
`connect`, `connect` can check the sender's predecessor for a completion scheduler
that defines `bulk_transform` and uses it if found.

The downside of this approach is that we will still have to support this API even when a
more general algorithm customization mechanism is available. That doesn't seem terribly
onerous to me, but that is for SG1/LEWG to decide.


## Impacts on hardware vendors

Without algorithm customization, manufacturers of special-purpose hardware accelerators
will not be able to ship a scheduler that both:

* works with any standard-conforming implementation of `std::execution`, and

* performs optimally on their hardware for all of the standard algorithms.

See [](#mitigating-factors) for some reasons why this is not as terrible as it sounds.


# Mitigating factors

The loss of direct support for sender algorithm customization is a blow to power users of
`std::execution`{.cpp}, but there are a few factors that mitigate the blow.

## Sender introspection

All of the senders returned from the standard algorithms are self-describing and can be
unpacked into their constituent parts with structured bindings. A sufficiently motivated
user can "customize" an algorithm by writing a recursive sender tree transformation,
explicitly transforming senders before launching them.

## Third party algorithms

The sender concepts and customization points make it possible for users to write their own
sender algorithms that interoperate with the standard ones. If a user wants to change the
behavior of the `then` algorithm in some way, they have the option of writing their own
and using it instead. I expect libraries of third-party algorithms to appear on GitHub in
time, as they tend to.

## Difficulties with proprietary extensions

Some execution contexts place extra-standard requirements on the code that executes on
them. For example, NVIDIA GPUs require device-accelerated code to be annotated with its
proprietary `__device__` annotation. Standard libraries are unlikely to ship
implementations of `std::execution` with such annotations. The consequence is that, rather
than shipping just a GPU scheduler with some algorithm customizations, a vendor like
NVIDIA is already committed to shipping its own complete implementation of
`std::execution` (in a different namespace, of course).

For such vendors, the inability to customize standard algorithms is a moot point. Since it
is _implementing_ the standard algorithms, the implementations can do whatever they want.


# The removal process

## Approach

The approach to removing sender algorithm customization is twofold:

- Remove those components that facilitate algorithm customization and their uses where it
  is easy to do so.

- In all other cases, turn normative mechanisms into non-normative ones so we can change
  them later. This results in smaller and safer wording changes and preserves the
  already agreed-upon semantics in a way that is easy to verify.

## Procedure

The steps for removing algorithm customization are detailed below.

1. Remove the type `default_domain`{.cpp} ([exec.domain.default]{.sref}).

2. Remove the functions:

   * `transform_sender`{.cpp} ([exec.snd.transform]{.sref}),
   * `transform_env`{.cpp} ([exec.snd.transform.env]{.sref}), and
   * `apply_sender`{.cpp} ([exec.snd.apply]{.sref}).

3. Remove the query object `get_domain`{.cpp} ([exec.get.domain]{.sref}).

4. Remove the exposition-only helpers:

   * _`completion-domain`_ ([exec.snd.expos]{.sref}/8-9),
   * _`get-domain-early`_ ([exec.snd.expos]{.sref}/13), and
   * _`get-domain-late`_ ([exec.snd.expos]{.sref}/14).

5. Change the functions `get_completion_signatures`{.cpp} ([exec.getcomplsigs]{.sref}) and
   `connect`{.cpp} ([exec.connect]{.sref}) to operate on a sender determined as follows
   instead of passing the sender through `transform_sender`{.cpp}:

   * If the sender has a tag with an exposition-only _`transform-sender`_ member function,
     pass the sender to this function with the receiver's environment and continue the
     operation on the resulting sender. This preserves the behavior of calling
     `transform_sender` with the `default_domain`.

   * Otherwise, perform the operation on the passed-in sender.

6. For the following algorithms that are currently expressed in terms of a sender
   transformation to a lowered form, move the lowering from
   `@_alg_@.transform_sender(sndr, env)`{.cpp} to `@_alg_@.@_transform-sender_@(sndr, env)`.

   * `starts_on`{.cpp} ([exec.starts.on]{.sref}),
   * `continues_on`{.cpp} ([exec.continues.on]{.sref}),
   * `on`{.cpp} ([exec.on]{.sref}),
   * `bulk`{.cpp} ([exec.bulk]{.sref}),
   * `when_all_with_variant`{.cpp} ([exec.when.all]{.sref}),
   * `stopped_as_optional`{.cpp} ([exec.stopped.opt]{.sref}), and
   * `stopped_as_error`{.cpp} ([exec.stopped.err]{.sref}).

7. For each sender adaptor algorithm in [exec.adapt]{.sref} that is specified to be
   expression-equivalent to some `transform_sender`{.cpp} invocation of the form:

   > ```cpp
   > transform_sender(@_`some-computed-domain`_@(), @_`make-sender`_@(tag, {args...}, sndr));
   > ```

   Change the expression to:

   > ```cpp
   > @_`make-sender`_@(tag, {args...}, sndr);
   > ```

   For example, in [exec.continues.on]{.sref}/3, the following:

   > ```cpp
   > transform_sender(@_`get-domain-early`_@(sndr), @_`make-sender`_@(continues_on, sch, sndr))
   > ```

   would be changed to:

   > ```cpp
   > @_`make-sender`_@(continues_on, sch, sndr)
   > ```

   Additionally, if there is some caveat of the form "except that `sndr`{.cpp} is
   evaluated only once," that caveat should be removed as appropriate.

8. Merge the `schedule_from`{.cpp} ([exec.schedule.from]{.sref}) and `continues_on`{.cpp}
   ([exec.continues.on]{.sref}) algorithms into one algorithm called `continues_on`{.cpp}.
   (Currently they are separate so that they can be customized independently; by default
   `continues_on`{.cpp} merely dispatches to `schedule_from`{.cpp}.)

9. Change [exec.sync.wait]{.sref} and [exec.sync.wait.var]{.sref} to dispatch directly to
   their default implementations instead of computing a domain and using `apply_sender`{.cpp} to
   dispatch to an implementation.

10. Fix a bug in the `on(sndr, sch, closure)` algorithm where a `write_env` is incorrectly
    changing the "current" scheduler before its child `continues_on` actually transfers to
    that scheduler. `continues_on` needs to know the scheduler on which it will be started
    in order to find customizations correctly in the future.

11. Tweak the wording of `parallel_scheduler`{.cpp} ([exec.par.scheduler]{.sref}) to
    indicate that it (`parallel_scheduler`) is permitted to run the `bulk`{.cpp} family of
    algorithms in parallel in accordance with those algorithms' semantics, rather than
    suggesting that those algorithms are "customized" for `parallel_scheduler`{.cpp}. The
    mechanism for such remains non-normative, however we specify the conditions under
    which the `parallel_scheduler` is guaranteed to run the `bulk` algorithms in parallel.
    (This is currently under-specified.)

12. Respecify `task_scheduler` in terms of `parallel_scheduler_backend` so that the
    `bulk` algorithms can be accelerated despite `task_scheduler`'s type-erasure.
    This addresses [LWG#4336](https://cplusplus.github.io/LWG/issue4336). As with
    `parallel_scheduler`, we specify the conditions under which `task_scheduler` is
    guaranteed to run the `bulk` algorithms in parallel.

13. From the `scheduler` concept, remove the required expression:

    > ```cpp
    > { auto(get_completion_scheduler<set_value_t>(get_env(schedule(std::forward<Sch>(sch))))) }
    >     -> same_as<remove_cvref_t<Sch>>;
    > ```

    Instead, add a semantic requirement that _if_ the above expression is well-formed,
    then it shall compare equal to `sch`. Additionally, require that that expression is
    well-formed for the `parallel_scheduler`, the `task_scheduler`, and `run_loop`'s
    scheduler, but not `inline_scheduler`. See [](#inline_scheduler) for the motivation
    behind these changes, but in short: the `inline_scheduler` does not know where it
    completes in C++26 but will in C++29.

14. _Optional, but recommended_: Change the `env<>::query`{.cpp} member function to accept
    optional additional arguments after the query tag. This restores the original design
    of `env` to that which was first proposed in [@P3325R1] and which was approved by LEWG
    straw poll in St Louis. As described in [](#restoring-algorithm-customization-in-c29),
    when asking a sender for its completion scheduler, the caller needs to pass extra
    information about where the operation will be started, and that will require
    `env<>::query` to accept extra arguments.

This is admittedly a lot of changes, but the first 9 changes represent a simplification
from the _status quo_, and the other changes are either neutral in terms of specification
or else correct an existing Library issue.

In the final accounting, the result of these changes will be a vastly simpler
specification for [exec].

# Restoring algorithm customization in C++29

For C++29, we want the sender algorithms in `std::execution` to be customizable,
with different implementations suited for different execution contexts. If we remove
customization for C++26, how do we add it back without breaking code?

Recall that many senders do not know where they will complete until they know where they
will be started, and that information is not currently provided when the sender is queried
for its completion scheduler. This is the shoal on which algorithm customization has
foundered, because without accurate information about where operations are executing, it
is impossible to pick the right algorithm implementation.

Once the problem is stated plainly, the fix (or at least a major part of it) is obvious:

::: callout

[When asking the sender where it will complete, _tell it where it will start_.]{.callout-context}

:::

The implication of this is that so-called "early" customization, performed when
constructing a sender, will not be coming back. The receiver's execution environment is
not known when constructing a sender. C++29 will bring back "late" customization only.


## Completion scheduler enhancements

A paper targetting C++29 will propose that we extend the `get_completion_scheduler` query
to support an optional environment argument. Given a sender `S` and receiver `R`, the query
would look like:

> ```cpp
> // Pass the sender's attributes and the receiver's environment when computing
> // the completion scheduler:
> auto sch = get_completion_scheduler<set_value_t>(get_env(S), get_env(R));
> ```

It will not be possible in C++26 to pass the receiver's environment in this way, making
this a conforming extension since it would not change the meaning of any existing code.

This change will also make it possible to provide a completion scheduler for the error
channel in more cases. That is often not possible today since many errors are reported
inline on the context on which the operation is started. The receiver's environment knows
where the operation will be started, so by passing it to the
`get_completion_scheduler<set_error_t>` query, the error completion scheduler is knowable.

::: callout

[Note]{.callout-header} [The paragraph above makes it sound like this would be changing
the behavior for the `get_completion_scheduler<set_error_t>(get_env(sndr))` query. But
that expression will behave as it always has. Only when called with the receiver's
environment will any new behavior manifest; hence, this change is a pure
extension.]{.callout-context}

:::

By the way, this extension to `get_completion_scheduler` motivates the change to
`env<>::query` described above in [](#the-removal-process). Although we could decide
to defer that change until it is needed in C++29, it seems best to me to make the
change now.

## Domains {#get-domain}

There are sender expressions that complete on an indeterminate scheduler based on runtime
factors; `when_all` is a good example. This is the problem the `get_domain` query solved.
So long as all of `when_all`'s child senders share a common domain tag -- a property of
the scheduler -- we know the domain on which the `when_all` operation will
complete, even though we do not know which scheduler it will complete on. The <u>domain</u>
controls algorithm selection, not the scheduler directly.

So the plan will be to bring back a `get_domain` query in C++29. Additionally, just as it
is necessary to have three `get_completion_scheduler` queries, one each for the three
different completion channels, it is necessary to have three `get_completion_domain`
queries for the times when the completion scheduler is indeterminate but the domain is
known.

::: callout

[Note]{.callout-header} [Above we say, "So long as all of `when_all`'s child senders share
a common domain tag [...]". This sounds like we are adding a new requirement to the
`when_all` algorithm. However, this requirement will be met for all existing uses of
`when_all`. Before C++29, all senders will be in the "default" domain, so they trivially
all share a common domain.]{.callout-context}

:::

Giving a non-default domain to a scheduler is the way to opt-in to algorithm
customization. Prior to C++29, there will be no `get_*domain` queries, hence the addition
of those queries in C++29 will not affect any existing schedulers. And the domain queries
will be so-called "forwarding" queries, meaning they will automatically be passed through
layers of sender adaptors. Users will not have to change their code in order for domain
information to be propagated. As a result, this change is a pure extension.


## Customizing `connect`

Since C++29 will support only late (`connect`-time) customization, customizing
an algorithm effectively amounts to customizing that algorithm's `connect` operation.
By default, `connect(sndr, rcvr)` calls `sndr.connect(rcvr)`, but in C++29 there
will be a way to do something different depending on the sender's attributes and
the receiver's environment.

`connect` will compute two domains, the "starting" domain and the (value) "completion"
domain:

| Domain kind       | Query                                                  |
|-------------------|--------------------------------------------------------|
| Starting domain   | `get_domain(get_env(rcvr))`                            |
| Completion domain | `get_completion_domain<set_value_t>(get_env(sndr), get_env(rcvr))` |

How `connect` will use this information to select an algorithm implementation is currently
under design. (See [](#appendix-a-the-planned-fix) for more information.) But at that point,
it is only a matter of mechanism. The key point is that `connect` has the information it
needs to dispatch accurately, and that we can make that addition without breaking code.
And we can.

## The parallel and task schedulers and `bulk`

Once we have a general mechanism for customizing algorithms, we can consider changing
`parallel_scheduler` and `task_scheduler` to use that mechanism to find parallel
implementations of the `bulk` algorithms. In C++26, it is unspecified precisely how those
schedulers accelerate `bulk`, and we can certainly leave it that way for C++29. No change
is often the safest change and always the easiest.

If we wanted to switch to using the new algorithm dispatch mechanics in C++29, I believe
we can do so with minimal impact on existing code. Any behavior change would be an
improvement, accelerating `bulk` operations that _should_ have been accelerated but
were not.

Consider the following sender:

> ```cpp
> starts_on(parallel_scheduler(), just() | bulk(fn))
> ```

In C++26, we can offer no iron-clad standard guarantee that this `bulk` operation will be
accelerated even though it is executing on the parallel scheduler. The predecessor
of `bulk`, `just()`, does not know where it will complete in C++26. There is no plumbing
yet to tell it that it will be started on the parallel scheduler. As a result, it is
QoI whether this `bulk` will execute in parallel or not.

But suppose we add a `get_completion_domain<set_value_t>` query to the
`parallel_scheduler` such that the query returns an instance of a new type:
`parallel_domain`. Now, when connecting the `bulk` sender, `connect` will ask for the
predecessor's domain, passing also the receiver's environment. Now the `just()` sender is
able to say where it completes: the domain where it starts, `get_domain(get_env(rcvr))`.
This will return `parallel_domain{}`. `connect` would then use that information to
find a parallel implementation of `bulk`.

As a result, in C++29 we could guarantee that this usage of `bulk` will be parallelized.
For some stdlib implementations, this would be a behavior change: what once executed
serially on a thread of the parallel scheduler now executes in parallel on many threads.
Can that break working code? Yes, but only code that had already violated the
preconditions of `bulk`: that `fn` can safely be called in parallel.

I do not believe this should be considered a breaking change, since any code that breaks
is already broken.

All of the above is true also for `task_scheduler`, which merely adds an indirection
to the call to `connect`. After the changes suggested by this paper, the `task_scheduler`
accelerates `bulk` in the same way as `parallel_scheduler`.

::: callout

[Note]{.callout-header} [If we assign `parallel_domain` to the `parallel_scheduler`, and
we _also_ add a requirement to `when_all` that all of its child operations share a common
domain (see [](#get-domain)), does that have the potential to break existing
code? It would not. We would make `parallel_domain` inherit from `default_domain` so
that `when_all` will compute the common domain as `default_domain` even if one child
completes in the `parallel_domain`.]{.callout-content}

:::

## `inline_scheduler`

The suggestion above to extend the `get_completion_scheduler<*>` query presents an
intriguing possibility for the `inline_scheduler`: the ability for it to report the
scheduler on which its scheduling operations complete!

Consider the sender `schedule(inline_scheduler{})`. Ask it where it completes today and it
will say, "I complete on the `inline_scheduler`.", which isn't terribly useful. However, if
you ask it, "Where will you complete -- and by the way you will be started on the
`parallel_scheduler`?", now that sender can report that it will complete on the
`parallel_scheduler`. 

The result is that code that uses the `inline_scheduler` will no longer cause the
_actual_ scheduler to be hidden.

This realization is the motivation behind the change to strike the
`get_completion_scheduler<set_value_t>(get_env(schedule(sch)))` requirement from the
`scheduler` concept. We want that expression to be ill-formed for the `inline_scheduler`.
Instead, we want the following query to be well-formed (in C++29):

> ```cpp
> get_completion_scheduler<set_value_t>(get_env(schedule(inline_scheduler())), get_env(rcvr))
> ```

That expression should be equivalent to `get_scheduler(get_env(rcvr))`, which says that
the sender of `inline_scheduler` completes wherever it is started.

::: callout

[Note]{.callout-header}[The reason we do not want `inline_scheduler` to have a
(largely meaningless) completion scheduler in C++26 is because we want it to have a
meaningful one in C++29. And it would be strange if asking for the completion scheduler
gave different answers depending on whether or not an environment was passed to the
query.
<br/>
This follows the general principle that if you query a sender's metadata early (sans
environment) and then later query it again with an environment, the answer should not
change. If the sender does not know the answer with certainty without an environment,
better for the expression to be ill-formed rather than returning potentially inaccurate
information.]{.callout-content}

:::


# Proposed wording

[In [execution.syn]{.sref}, make the following changes:]{.ednote}

> ```cpp
> @[&hellip; as before &hellip;]{.blue}@
>
> namespace std::execution {
>   // [exec.queries], queries
>   @@[```struct get_domain_t { @_`unspecified`_@ };```]{.rm}@@
>   struct get_scheduler_t { @_`unspecified`_@ };
>   struct get_delegation_scheduler_t { @_`unspecified`_@ };
>   struct get_forward_progress_guarantee_t { @_`unspecified`_@ };
>   template<class CPO>
>     struct get_completion_scheduler_t { @_`unspecified`_@ };
>   struct get_await_completion_adaptor_t { @_`unspecified`_@ };
>
>   @@[```inline constexpr get_domain_t get_domain{};```]{.rm}@@
>   inline constexpr get_scheduler_t get_scheduler{};
>   inline constexpr get_delegation_scheduler_t get_delegation_scheduler{};
>   enum class forward_progress_guarantee;
>   inline constexpr get_forward_progress_guarantee_t get_forward_progress_guarantee{};
>   template<class CPO>
>     constexpr get_completion_scheduler_t<CPO> get_completion_scheduler{};
>   inline constexpr get_await_completion_adaptor_t get_await_completion_adaptor{};
>
> @[&hellip; as before &hellip;]{.blue}@
>
>   // [exec.env], class template env
>   template<queryable... Envs>
>     struct env;
>
>   @@[_```// [exec.domain.default], execution domains```_]{.rm}@@
>   @@[```struct default_domain;```]{.rm}@@
>
>   // [exec.sched], schedulers
>   struct scheduler_t {};
>
> @[&hellip; as before &hellip;]{.blue}@
>
>   template<sender Sndr>
>     using tag_of_t = @_`see below`_@;
>
>   @@[_```// [exec.snd.transform], sender transformations```_]{.rm}@@
>   @@[```template<class Domain, sender Sndr, queryable... Env>```]{.rm}@@
>       @@[```requires (sizeof...(Env) <= 1)```]{.rm}@@
>     @@[```constexpr sender decltype(auto) transform_sender(```]{.rm}@@
>       @@[```Domain dom, Sndr&& sndr, const Env&... env) noexcept(@_`see below`_@);```]{.rm}@@
>
>   @@[_```// [exec.snd.transform.env], environment transformations```_]{.rm}@@
>   @@[```template<class Domain, sender Sndr, queryable Env>```]{.rm}@@
>     @@[```constexpr queryable decltype(auto) transform_env(```]{.rm}@@
>       @@[```Domain dom, Sndr&& sndr, Env&& env) noexcept;```]{.rm}@@
>
>   @@[_```// [exec.snd.apply], sender algorithm application```_]{.rm}@@
>   @@[```template<class Domain, class Tag, sender Sndr, class... Args>```]{.rm}@@
>     @@[```constexpr decltype(auto) apply_sender(```]{.rm}@@
>       @@[```Domain dom, Tag, Sndr&& sndr, Args&&... args) noexcept(@_`see below`_@);```]{.rm}@@
>
>   // [exec.connect], the connect sender algorithm
>   struct connect_t;
>   inline constexpr connect_t connect{};
>
> @[&hellip; as before &hellip;]{.blue}@
> ```


[Remove subsection [exec.get.domain]{.sref}.]{.ednote}


[In [exec.sched]{.sref}, change paragraphs 1 and 5 and strike paragraph 6 as
follows:]{.ednote}

> 1. The `scheduler` concept defines the requirements of a scheduler type
>    ([exec.async.ops]{.sref}). `schedule` is a customization point object that accepts a
>    scheduler. A valid invocation of `schedule` is a schedule-expression.
>
>    > ```cpp
>    > namespace std::execution {
>    >   template<class Sch>
>    >     concept scheduler =
>    >       derived_from<typename remove_cvref_t<Sch>::scheduler_concept, scheduler_t> &&
>    >       @_queryable_@<Sch> &&
>    >       requires(Sch&& sch) {
>    >         { schedule(std::forward<Sch>(sch)) } -> sender;
>    >         @[`{ auto(get_completion_scheduler<set_value_t>(`]{.rm}@
>    >             @[`get_env(schedule(std::forward<Sch>(sch))))) }`]{.rm}@
>    >               @[`-> same_as<remove_cvref_t<Sch>>;`]{.rm}@
>    >       } &&
>    >       equality_comparable<remove_cvref_t<Sch>> &&
>    >       copyable<remove_cvref_t<Sch>>;
>    > }
>    > ```
>
> > [&hellip; as before &hellip;]{.blue}
>
> 5. For a given scheduler expression `sch`, [if]{.add} the expression
>    ```@[auto(]{.add}@get_completion_scheduler<set_value_t>(get_env(schedule(sch)))@[)]{.add}@```{.cpp}
>    [is well-formed, it shall have type `remove_cvref_t<Sch>` and]{.add} shall compare
>    equal to `sch`.
>
> ::: rm
>
> 6. For a given scheduler expression `sch`, if the expression `get_domain(sch)`{.cpp} is
>    well-formed, then the expression `get_domain(get_env(schedule(sch)))`{.cpp} is also
>    well-formed and has the same type.
>
> :::



[In [exec.snd.general]{.sref}, change paragraph 1 as follows:]{.ednote}

> 1. Subclauses [exec.factories]{.sref} and [exec.adapt]{.sref} define [customizable]{.rm}
>    algorithms that return senders. [Each algorithm has a default implementation.]{.rm} Let
>    `sndr`{.cpp} be the result of an invocation of such an algorithm or an object equal to the
>    result ([concepts.equality]{.sref}), and let `Sndr`{.cpp} be `decltype((sndr))`{.cpp}. Let `rcvr`{.cpp}
>    be a receiver of type `Rcvr`{.cpp} with associated environment env of type `Env`{.cpp} such that
>    `sender_to<Sndr, Rcvr>`{.cpp} is `true`{.cpp}. [For the default implementation of the algorithm
>    that produced `sndr`{.cpp}, c]{.rm}[C]{.add}onnecting `sndr`{.cpp} to `rcvr`{.cpp} and starting the
>    resulting operation state ([exec.async.ops]{.sref}) necessarily results in the
>    potential evaluation ([basic.def.odr]{.sref}) of a set of completion operations whose
>    first argument is a subexpression equal to `rcvr`{.cpp}. Let `Sigs`{.cpp} be a pack of completion
>    signatures corresponding to this set of completion operations, and let `CS`{.cpp} be the type
>    of the expression `get_completion_signatures<Sndr, Env>()`{.cpp}. Then `CS`{.cpp} is a
>    specialization of the class template `completion_signatures`{.cpp} ([exec.cmplsig]{.sref}),
>    the set of whose template arguments is `Sigs`{.cpp}. If none of the types in `Sigs`{.cpp} are
>    dependent on the type `Env`{.cpp}, then the expression `get_completion_signatures<Sndr>()`{.cpp} is
>    well-formed and its type is `CS`{.cpp}. [If a user-provided implementation of the algorithm
>    that produced `sndr`{.cpp} is selected instead of the default:]{.rm}
>
>    - [[1.1]{.pnum} Any completion signature that is in the set of types denoted by
>      `completion_signatures_of_t<Sndr, Env>`{.cpp} and that is not part of `Sigs`{.cpp} shall
>      correspond to error or stopped completion operations, unless otherwise specified.]{.rm}
>
>    - [[1.2]{.pnum} If none of the types in `Sigs`{.cpp} are dependent on the type `Env`{.cpp}, then
>      `completion_signatures_of_t<Sndr>`{.cpp} and `completion_signatures_of_t<Sndr, Env>`{.cpp} shall
>      denote the same type.]{.rm}

[Change [exec.snd.expos]{.sref} paragraph 6 as follows:]{.ednote}

> 6. For a scheduler `sch`{.cpp}, ```@_`SCHED-ATTRS`_@(sch)```{.cpp} is [an expression `o1`{.cpp} whose type
>    satisfies _`queryable`_ such that `o1.query(get_completion_scheduler<Tag>)`{.cpp} is an
>    expression with the same type and value as `sch`]{.rm} [equivalent to
>    ```@_`MAKE-ENV`_@(get_completion_scheduler<set_value_t>, sch)```]{.add} [where `Tag`{.cpp} is one of
>    `set_value_t`{.cpp} or `set_stopped_t`, and such that `o1.query(get_domain)`{.cpp} is
>    expression-equivalent to `sch.query(get_domain)`]{.rm}. ```@_`SCHED-ENV`_@(sch)```{.cpp} is
>    [an expression `o2`{.cpp} whose type satisfies _`queryable`_ such that
>    `o2.query(get_scheduler)`{.cpp} is a prvalue with the same type and value as `sch`{.cpp}, and
>    such that `o2.query(get_domain)`{.cpp} is expression-equivalent to
>    `sch.query(get_domain)`]{.rm} [equivalent to
>    ```@_`MAKE-ENV`_@(get_scheduler, sch)```]{.add}.

[Remove the prototype of the exposition-only _`completion-domain`_ function just before
[exec.snd.expos]{.sref} paragraph 8, and with it remove paragraphs 8 and 9, which specify
the function's behavior.]{.ednote}

[Remove [exec.snd.expos]{.sref} paragraphs 13 and 14 and the prototypes for the
_`get-domain-early`_ and _`get-domain-late`_ functions.]{.ednote}

[Remove subsection [exec.domain.default]{.sref}.]{.ednote}

[Remove subsection [exec.snd.transform]{.sref}.]{.ednote}

[Remove subsection [exec.snd.transform.env]{.sref}.]{.ednote}

[Remove subsection [exec.snd.apply]{.sref}.]{.ednote}

[Change [exec.getcomplsigs]{.sref} as follows:]{.ednote}

> 1. Let _`except`_ be an rvalue subexpression of an unspecified class type _`Except`_ such
>    that ```move_constructible<@_`Except`_@> && derived_from<@_`Except`_@, exception>```{.cpp}
>    is `true`{.cpp}. Let ```@_`CHECKED-COMPLSIGS`_@(@_`e`_@)```{.cpp} be _`e`_ if _`e`_ is
>    a core constant expression whose type satisfies _`valid-completion-signatures`_;
>    otherwise, it is the following expression:
>
>    > ```cpp
>    > (@_`e`_@, throw @_`except`_@, completion_signatures())
>    > ```
>
>    Let ```@_`get-complsigs`_@<Sndr, Env...>()```{.cpp} be expression-equivalent to
>    ```remove_reference_t<Sndr>​::​template get_completion_signatures<Sndr, Env...>()```{.cpp}.
>    [Let `NewSndr`{.cpp} be `Sndr`{.cpp} if `sizeof...(Env) == 0`{.cpp} is `true`;
>    otherwise, ```decltype(@_`s`_@)```{.cpp} where _`s`_ is the following expression:]{.rm}
>    [Let `NewSndr`{.cpp} be
>    ```decltype(tag_of_t<Sndr>().@_`transform-sender`_@(declval<Sndr>(), declval<Env>()...))```
>    if that expression is well-formed, and `Sndr` otherwise.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > @@[```transform_sender(```]{.rm}@@
>    >   @@[```@_`get-domain-late`_@(declval<Sndr>(), declval<Env>()...),```]{.rm}@@
>    >   @@[```declval<Sndr>(),```]{.rm}@@
>    >   @@[```declval<Env>()...)```]{.rm}@@
>    > ```
>
>    :::
>
> 2. _Constraints_: `sizeof...(Env) <= 1`{.cpp} is `true`{.cpp}.
>
> 3. _Effects_: Equivalent to:  [&hellip; as before &hellip;]{.blue}


[Change [exec.connect]{.sref} as follows:]{.ednote}

> 1. `connect` connects ([exec.async.ops]{.sref}) a sender with a receiver.
>
> 2. The name `connect` denotes a customization point object. For subexpressions `sndr` and
>    `rcvr`, let `Sndr` be `decltype((sndr))` and `Rcvr` be `decltype((rcvr))`[,]{.rm}[;]{.add} let
>    `new_sndr` be the expression
>    [```transform_sender(decltype(@_`get-domain-late`_@(sndr, get_env(rcvr))){}, sndr, get_env(rcvr))```{.cpp}]{.rm}
>    [```tag_of_t<Sndr>().@_`transform-sender`_@(sndr, get_env(rcvr))```{.cpp} if that
>    expression is well-formed, and `sndr` otherwise;]{.add}
>    and let `DS` and `DR` be ```decay_t<decltype((new_sndr))>```{.cpp} and
>    `decay_t<Rcvr>`, respectively.
>
> 3. Let _`connect-awaitable-promise`_ be
>    [&hellip; as before &hellip;]{.blue}


[Change [exec.schedule]{.sref} paragraph 4 as follows:]{.ednote}

4. If the expression

   > ```cpp
   > get_completion_scheduler<set_value_t>(get_env(sch.schedule()))@[` == sch`]{.rm}@
   > ```

   is [ill-formed or]{.rm} [well-formed and does not]{.add} evaluate[s]{.rm} to
   [`false`]{.rm} [`sch`]{.add}, the behavior of calling `schedule(sch)` is undefined.

[From [exec.adapt.general]{.sref}, strike paragraph (3.6) as follows:]{.ednote}

> 3. Unless otherwise specified:
>
>    [&hellip; as before &hellip;]{.blue}
>
>    - [3.5]{.pnum} An adaptor whose child senders are all non-dependent
>      ([exec.async.ops]{.sref}) is itself non-dependent.
>
>    - [3.6]{.pnum} [These requirements apply to any function that is selected by the
>      implementation of the sender adaptor.]{.rm}
>
>    - [3.7]{.pnum} _Recommended practice_: Implementations should use the completion
>      signatures of the adaptors to communicate type errors to users and to propagate any such
>      type errors from child senders.

[Change [exec.starts.on]{.sref} paragraph 3 as follows:]{.ednote}

> 3. Otherwise, the expression `starts_on(sch, sndr)`{.cpp} is expression-equivalent to[:]{.rm}
>    [```@_`make-sender`_@(starts_on, sch, sndr)```{.cpp}.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > transform_sender(
>    >   @_`query-with-default`_@(get_domain, sch, default_domain()),
>    >   @_`make-sender`_@(starts_on, sch, sndr))
>    > ```
>
>    [except that `sch` is evaluated only once.]{.rm}
>
>    :::
>
> 4. Let `out_sndr` and `env` be subexpressions such that `OutSndr` is `decltype((out_sndr))`{.cpp}. If
>    ```@_`sender-for`_@<OutSndr, starts_on_t>``` is `false`, then the [expressions
>    `starts_on.transform_env(out_sndr, env)` and]{.rm} [expression]{.add}
>    ```starts_on.@[transform_sender]{.rm}[_`transform-sender`_]{.add}@(out_sndr, env)```
>    [are]{.rm} [is]{.add} ill-formed; otherwise [it is equivalent to:]{.add}
>
>    ::: rm
>
>    - [4.1]{.pnum} `starts_on.transform_env(out_sndr, env)` is equivalent to:
>
>      > ```cpp
>      > auto&& [_, sch, _] = out_sndr;
>      > return @_`JOIN-ENV`_@(@_`SCHED-ENV`_@(sch), @_`FWD-ENV`_@(env));
>      > ```
>
>    - [4.2]{.pnum} `starts_on.transform_sender(out_sndr, env)` is equivalent to:
>
>    :::
>
> > > ```cpp
> > > auto&& [_, sch, sndr] = out_sndr;
> > > return let_value(
> > >   schedule(sch),
> > >   [sndr = std::forward_like<OutSndr>(sndr)]() mutable
> > >     noexcept(is_nothrow_move_constructible_v<decay_t<OutSndr>>) {
> > >     return std::move(sndr);
> > >   });
> > > ```
>
> 5. Let `out_sndr` be
>    [&hellip; as before &hellip;]{.blue}


[Remove subsection [exec.continues.on]{.sref}]{.ednote}

[Change [exec.schedule.from]{.sref} to [exec.continues.on] and change it as follows:]{.ednote}

> **33.9.12.[7]{.rm}[6]{.add} ```execution::@[`schedule_from`]{.rm}[`continues_on`]{.add}@             ```{.cpp} [exec[.schedule.from]{.rm}[.continues.on]{.add}]**
>
>
> 1. [`schedule_from`]{.rm}[`continues_on`]{.add} schedules work dependent on the completion
>    of a sender onto a scheduler's associated execution resource.
>
>    [[_Note 1_:` schedule_from` is not meant to be used in user code; it is used in the
>    implementation of `continues_on`. — end note]]{.rm}
>
> 2. The name [`schedule_from`]{.rm}[`continues_on`]{.add} denotes a customization point
>    object. For some subexpressions `sch` and `sndr`, let `Sch` be `decltype((sch))` and
>    `Sndr` be `decltype((sndr))`. If `Sch` does not satisfy scheduler, or `Sndr` does not
>    satisfy `sender`,
>    [`schedule_from(sch, sndr)`{.cpp}]{.rm}[`continues_on(sndr, sch)`{.cpp}]{.add} is
>    ill-formed.
>
> 3. Otherwise, the expression
>    [`schedule_from(sch, sndr)`{.cpp}]{.rm}[`continues_on(sndr, sch)`{.cpp}]{.add} is
>    expression-equivalent to[:]{.rm} [```@_`make-sender`_@(continues_on, sch, sndr)```{.cpp}]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > transform_sender(
>    >    @_`query-with-default`_@(get_domain, sch, default_domain()),
>    >    @_`make-sender`_@(schedule_from, sch, sndr))
>    > ```
>
>    except that sch is evaluated only once.
>
>    :::
>
> 4. The exposition-only class template _`impls-for`_ ([exec.snd.general]{.sref}) is
>    specialized for [`schedule_from_t`]{.rm}[`continues_on_t`]{.add} as follows:
>
>    > ```cpp
>    > namespace std::execution {
>    >    template<>
>    >    struct @_`impls-for`_@<@[`schedule_from_t`]{.rm}[`continues_on_t`]{.add}@> : @_`default-impls`_@ {
>    >       static constexpr auto @_`get-attrs`_@ = @_`see below`_@;
>    >       static constexpr auto @_`get-state`_@ = @_`see below`_@;
>    >       static constexpr auto @_`complete`_@ = @_`see below`_@;
>    >
>    >       template<class Sndr, class... Env>
>    >          static consteval void @_`check-types`_@();
>    >    };
>    > }
>    > ```
>
> 5. The member ```@_`impls-for`_@<@[`schedule_from_t`]{.rm}[`continues_on_t`]{.add}@>​::@_`​get-attrs`_@```{.cpp}
>    is initialized with a callable object equivalent to the following lambda:
>
>    > ```cpp
>    > [](const auto& data, const auto& child) noexcept -> decltype(auto) {
>    >    return @_`JOIN-ENV`_@(@_`SCHED-ATTRS`_@(data), @_`FWD-ENV`_@(get_env(child)));
>    > }
>    > ```
>
> 6. The member ```@_`impls-for`_@<@[`schedule_from_t`]{.rm}[`continues_on_t`]{.add}@>​::@_`​get-state`_@```{.cpp}
>    is initialized with a callable object equivalent to the following lambda:
>
>    [&hellip; as before &hellip;]{.blue}
>
> > ```cpp
> > template<class Sndr, class... Env>
> >   static consteval void @_`check-types`_@();
> > ```
>
> [&hellip; as before &hellip;]{.blue}
>
> 12. The member ```@_`impls-for`_@<@[`schedule_from_t`]{.rm}[`continues_on_t`]{.add}@>​::@_`complete`_@```{.cpp}
>     is initialized with a callable object equivalent to the following lambda:
>
>     [&hellip; as before &hellip;]{.blue}
>
> 13. Let `out_sndr` be a subexpression denoting a sender returned from
>     [`schedule_from(sch, sndr)`]{.rm}[`continues_on(sndr, sch)`]{.add} or one equal to
>     such, and let `OutSndr` be the type `decltype((out_sndr))`. Let `out_rcvr` be
>     [&hellip; as before &hellip;]{.blue}


[Change [exec.on]{.sref} paragraphs 3-8 as follows:]{.ednote}


> 3. Otherwise, if `decltype((sndr))` satisfies `sender`, the expression `on(sch, sndr)` is
>    expression-equivalent to[:]{.rm} [```@_`make-sender`_@(on, sch, sndr)```{.cpp}.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > transform_sender(
>    >    @_`query-with-default`_@(get_domain, sch, default_domain()),
>    >    @_`make-sender`_@(on, sch, sndr))
>    > ```
>
>    except that `sch` is evaluated only once.
>
>    :::
>
>
> 4. For subexpressions `sndr`, `sch`, and `closure`, if
>
>    - [4.1]{.pnum} `decltype((sch))` does not satisfy `scheduler`, or
>
>    - [4.2]{.pnum} `decltype((sndr))` does not satisfy `sender`, or
>
>    - [4.3]{.pnum} `closure` is not a pipeable sender adaptor closure object
>      ([exec.adapt.obj]), the expression `on(sndr, sch, closure)` is ill-formed;
>      otherwise, it is expression-equivalent to[:]{.rm}
>      [```@_`make-sender`_@(on, @_`product-type`_@{sch, closure}, sndr)```{.cpp}.]{.add}
>
>      ::: rm
>
>      > ```cpp
>      > transform_sender(
>      >    @_`get-domain-early`_@(sndr),
>      >    @_`make-sender`_@(on, @_`product-type`_@{sch, closure}, sndr))
>      > ```
>
>      except that `sndr` is evaluated only once.
>
>      :::
>
> 5. Let `out_sndr` and `env` be subexpressions, let `OutSndr` be `decltype((out_sndr))`{.cpp},
>    and let `Env` be `decltype((env))`{.cpp}. If ```@_`sender-for`_@<OutSndr, on_t>```{.cpp}
>    is `false`, then the [expressions `on.transform_env(out_sndr, env)`{.cpp} and]{.rm}
>    [expression]{.add} ```on.@[`transform_sender`]{.rm}[_`transform-sender`_]{.add}@(out_sndr, env)```{.cpp}
>    [are]{.rm} [is]{.add} ill-formed.
>
> 6. Otherwise: Let _`not-a-scheduler`_ be an unspecified empty class type.
>
> ::: rm
>
> 7. The expression `on.transform_env(out_sndr, env)` has effects equivalent to:
>
>    > ```cpp
>    > auto&& [_, data, _] = out_sndr;
>    > if constexpr (scheduler<decltype(data)>) {
>    >   return @_`JOIN-ENV`_@(@_`SCHED-ENV`_@(std::forward_like<OutSndr>(data)), @_`FWD-ENV`_@(std::forward<Env>(env)));
>    > } else {
>    >   return std::forward<Env>(env);
>    > }
>    > ```
>
> :::
>
> 8. The expression ```on.@[`transform_sender`]{.rm}[_`transform-sender`_]{.add}@(out_sndr, env)```{.cpp}
>    has effects equivalent to:
>
>    > ```cpp
>    > auto&& [_, data, child] = out_sndr;
>    > if constexpr (scheduler<decltype(data)>) {
>    >    auto orig_sch =
>    >       @_`query-with-default`_@(get_scheduler, env, @_`not-a-scheduler`_@());
>    >
>    >    if constexpr (same_as<decltype(orig_sch), @_`not-a-scheduler`_@>) {
>    >       return @_`not-a-sender`_@{};
>    >    } else {
>    >       return continues_on(
>    >          starts_on(std::forward_like<OutSndr>(data), std::forward_like<OutSndr>(child)),
>    >          std::move(orig_sch));
>    >    }
>    > } else {
>    >    auto& [sch, closure] = data;
>    >    auto orig_sch = @_`query-with-default`_@(
>    >       get_completion_scheduler<set_value_t>,
>    >       get_env(child),
>    >       @_`query-with-default`_@(get_scheduler, env, @_`not-a-scheduler`_@()));
>    >
>    >    if constexpr (same_as<decltype(orig_sch), @_`not-a-scheduler`_@>) {
>    >       return @_`not-a-sender`_@{};
>    >    } else {
>    >       return @[`write_env`]{.rm} [`continues_on`]{.add}@(
>    >          @[`continues_on`]{.rm} [`write_env`]{.add}@(
>    >             std::forward_like<OutSndr>(closure)(
>    >                continues_on(
>    >                   write_env(std::forward_like<OutSndr>(child), @_`SCHED-ENV`_@(orig_sch)),
>    >                   sch)),
>    >             @[`orig_sch`]{.rm}@ @@[```@_`SCHED-ENV`_@(sch)```]{.add}@@),
>    >          @@[```@_`SCHED-ENV`_@(sch)```]{.rm}@@ @[`orig_sch`]{.add}@);
>    >    }
>    > }
>    > ```


[Change [exec.then]{.sref} paragraph 3 as follows:]{.ednote}

> 3. Otherwise, the expression ```@_`then-cpo`_@(sndr, f)```{.cpp} is expression-equivalent
>    to[:]{.rm} [```@_`make-sender`_@(@_`then-cpo`_@, f, sndr)```{.cpp}.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > transform_sender(@_`get-domain-early`_@(sndr), @_`make-sender`_@(@_`then-cpo`_@, f, sndr))
>    > ```
>
>    except that `sndr` is evaluated only once.
>
>    :::


[Change [exec.let]{.sref} paragraphs 2-4 as follows:]{.ednote}

> 2. For `let_value`, `let_error`, and `let_stopped`, let _`set-cpo`_ be `set_value`,
>    `set_error`, and `set_stopped`, respectively. Let the expression _`let-cpo`_ be one of
>    `let_value`, `let_error`, or `let_stopped`. For a subexpression `sndr`, let
>    ```@_`let-env`_@(sndr)```{.cpp} be expression-equivalent to
>    the first well-formed expression below:
>
>    - [2.1]{.pnum} ```@_`SCHED-ENV`_@(@_`get_completion_scheduler`_@<@_`decayed-typeof`_@<@_`set-cpo`_@>>(get_env(sndr)))```{.cpp}
>
>    ::: rm
>
>    - [2.2]{.pnum} ```@_`MAKE-ENV`_@(get_domain, get_domain(get_env(sndr)))```{.cpp}
>
>    :::
>
>    - [2.3]{.pnum} `(void(sndr), env<>{})`{.cpp}
>
> 3. The names `let_value`, `let_error`, and `let_stopped` denote
>    [&hellip; as before &hellip;]{.blue}
>
> 4. Otherwise, the expression ```@_`let-cpo`_@(sndr, f)```{.cpp} is expression-equivalent
>    to[:]{.rm} [```@_`make-sender`_@(@_`let-cpo`_@, f, sndr)```{.cpp}.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > transform_sender(@_`get-domain-early`_@(sndr), @_`make-sender`_@(@_`let-cpo`_@, f, sndr))
>    > ```
>
>    except that `sndr` is evaluated only once.
>
>    :::

<a name="proposed-wording-for-bulk"></a>

[Change [exec.bulk]{.sref} paragraphs 3 and 4 and insert paragraphs 5 and 6 as
follows:]{.ednote}

> 3. Otherwise, the expression ```@_`bulk-algo`_@(sndr, policy, shape, f)```{.cpp} is
>    expression-equivalent to:
>
>    ```cpp
>    @@[```transform_sender(@_`get-domain-early`_@(sndr),```{.cpp}]{.rm}@@ @_`make-sender`_@(
>       @_`bulk-algo`_@, @_`product-type`_@<@_`see below`_@, Shape, Func>{policy, shape, f}, sndr)@[`)`]{.rm}@
>    ```
>
>    [except that `sndr` is evaluated only once.]{.rm} The first template argument of
>    _`product-type`_ is `Policy` if `Policy` models `copy_constructible`, and `const Policy&`
>    otherwise.
>
> 4. Let `sndr` [and `env` be subexpressions]{.rm} [be an expression]{.add} such that
>    `Sndr` is `decltype((sndr))`. If ```@_`sender-for`_@<Sndr, bulk_t>```{.cpp} is
>    `false`, then the expression [`bulk.transform_sender(sndr, env)`{.cpp}]{.rm}
>    [```@_`as-bulk-chunked`_@(sndr)```{.cpp}]{.add} is ill-formed;
>    otherwise, it is equivalent to:
>
>    > ```cpp
>    > auto [_, data, child] = sndr;
>    > auto& [policy, shape, f] = data;
>    > auto new_f = [func = std::move(f)](Shape begin, Shape end, auto&&... vs)
>    >     noexcept(noexcept(f(begin, vs...))) {
>    >   while (begin != end)
>    >     func(begin++, vs...);
>    > }
>    > return bulk_chunked(std::move(child), policy, shape, std::move(new_f));
>    > ```
>
>    [[This causes the `bulk(sndr, policy, shape, f)` sender to be expressed in terms
>    of `bulk_chunked(sndr, policy, shape, f)` when it is connected to a receiver [whose
>    execution domain does not customize `bulk`]{.rm}.]{.note}]{.rm}
>
> ::: add
>
> 5. Let `sndr` and `env` be subexpressions, let `Sndr` be `decltype((sndr))`, and let
>    `sch` be expression-equivalent to
>    ```get_completion_scheduler<set_value_t>(get_env(sndr.@_`get`_@<2>()))```{.cpp}. If
>    ```@_`sender-for`_@<Sndr, @_`decayed-typeof`_@<@_`bulk-algo`_@>>```{.cpp} is `false`,
>    the expression ```@_`bulk-algo`_@.@_`transform-sender`_@(sndr, env)```{.cpp} is
>    ill-formed; otherwise, it is expression-equivalent to:
>
>    - [6.1]{.pnum} ```sch.@_`bulk-transform`_@(sndr, env)```{.cpp} if that expression is
>      well-formed; otherwise,
>
>    - [6.2]{.pnum} ```sch.@_`bulk-transform`_@(@_`as-bulk-chunked`_@(sndr), env)```{.cpp}
>      if that expression is well-formed; otherwise,
>
>    - [6.3]{.pnum} ```@_`bulk-algo`_@.@_`transform-sender`_@(sndr, env)```{.cpp} is
>      ill-formed.
>
> :::

[Change [exec.when.all]{.sref} as follows:]{.ednote}

> 1. `when_all` and `when_all_with_variant` both [&hellip; as before &hellip;]{.blue}
>
> 2. The names `when_all` and `when_all_with_variant` denote customization point objects.
>    Let `sndrs` be a pack of subexpressions[,]{.rm} [and]{.add} let `Sndrs` be a pack of
>    the types `decltype((sndrs))...`{.cpp}[, and let `CD` be the type
>    ```common_type_t<decltype(@_`get-domain-early`_@(sndrs))...>```{.cpp}. Let `CD2` be
>    `CD` if `CD` is well-formed, and `default_domain` otherwise]{.rm}. The expressions
>    `when_all(sndrs...)` and `when_all_with_variant(sndrs...)` are ill-formed if any of the
>    following is `true`:
>
>    - [2.1]{.pnum} `sizeof...(sndrs)`{.cpp} is `0`{.cpp}, or
>
>    - [2.2]{.pnum} `(sender<Sndrs> && ...)`{.cpp} is `false`{.cpp}.
>
> 3. The expression `when_all(sndrs...)` is expression-equivalent to[:]{.rm}
>    [```@_`make-sender`_@(when_all, {}, sndrs...)```.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > transform_sender(CD2(), @_`make-sender`_@(when_all, {}, sndrs...))
>    > ```
>
>    :::
>
> 4. The exposition-only class template _`impls-for`_ ([exec.snd.general]{.sref}) is
>    specialized for `when_all_t` as follows:
>
>    > ```cpp
>    > namespace std::execution {
>    >    template<>
>    >    struct @_`impls-for`_@<when_all_t> : @_`default-impls`_@ {
>    >       @@[```static constexpr auto @_`get-attrs`_@ = @_`see below`_@;```]{.rm}@@
>    >       static constexpr auto @_`get-env`_@ = @_`see below`_@;
>    >       static constexpr auto @_`get-state`_@ = @_`see below`_@;
>    >       static constexpr auto @_`start`_@ = @_`see below`_@;
>    >       static constexpr auto @_`complete`_@ = @_`see below`_@;
>    >
>    >       template<class Sndr, class... Env>
>    >          static consteval void @_`check-types`_@();
>    >    };
>    > }
>    > ```
>
> [&hellip; as before &hellip;]{.blue}
>
> 9. _Throws_: Any exception thrown as a result of evaluating the _Effects_[, or an exception
>    of an unspecified type derived from `exception` when `CD` is ill-formed]{.rm}.
>
> ::: rm
>
> 10. The member ```@_`impls-for`_@<when_all_t>​::@_`​get-attrs`_@```{.vpp} is initialized
>     with a callable object equivalent to the following lambda expression:
>
>     > ```cpp
>     > [](auto&&, auto&&... child) noexcept {
>     >    if constexpr (same_as<CD, default_domain>) {
>     >       return env<>();
>     >    } else {
>     >       return @_`MAKE-ENV`_@(get_domain, CD());
>     >    }
>     > }
>     > ```
>
> :::
>
> [&hellip; as before &hellip;]{.blue}
>
> 19. The expression `when_all_with_variant(sndrs...)`{.cpp} is expression-equivalent
>     to[:]{.rm} [```@_`make-sender`_@(when_all_with_variant, {}, sndrs...)```{.cpp}.]{.add}
>
>     ::: rm
>
>     > ```cpp
>     > transform_sender(CD2(), @_`make-sender`_@(when_all_with_variant, {}, sndrs...));
>     > ```
>
>     :::
>
> 20. Given subexpressions `sndr` and `env`, if
>     ```@_`sender-for`_@<decltype((sndr)), when_all_with_variant_t>```{.cpp} is
>     `false`{.cpp}, then the expression
>     ```when_all_with_variant.@[`transform_sender`]{.rm}[_`transform-sender`_]{.add}@(sndr, env)```{.cpp}
>     is ill-formed; otherwise, it is equivalent to:
>
>     > ```cpp
>     > auto&& [_, _, ...child] = sndr;
>     > return when_all(into_variant(std::forward_like<decltype((sndr))>(child))...);
>     > ```
>
>     [_Note 1_: This causes the `when_all_with_variant(sndrs...)`{.cpp} sender to become
>     `when_all(into_variant(sndrs)...)`{.cpp} when it is connected with a receiver [whose
>     execution domain does not customize `when_all_with_variant`]{.rm}. — _end note_]

[Change [exec.into.variant]{.sref} paragraph 3 as follows:]{.ednote}

> 3. Otherwise, the expression `into_variant(sndr)`{.cpp} is expression-equivalent to[:]{.rm}
>    [```@_`make-sender`_@(into_variant, {}, sndr)```{.cpp}.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > transform_sender(@_`get-domain-early`_@(sndr), @_`make-sender`_@(into_variant, {}, sndr))
>    > ```
>
>    except that `sndr` is only evaluated once.
>
>    :::

[Change [exec.stopped.opt]{.sref} paragraphs 2 and 4 as follows:]{.ednote}

> 2. The name `stopped_as_optional` denotes a pipeable sender adaptor object. For a
>    subexpression `sndr`, let `Sndr` be `decltype((sndr))`{.cpp}. The expression
>    `stopped_as_optional(sndr)` is expression-equivalent to[:]{.rm}
>    [```@_`make-sender`_@(stopped_as_optional, {}, sndr)```{.cpp}.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > transform_sender(@_`get-domain-early`_@(sndr), @_`make-sender`_@(stopped_as_optional, {}, sndr))
>    > ```
>
>    except that `sndr` is only evaluated once.
>
>    :::
>
> 3. The exposition-only class template _`impls-for`_ [&hellip; as before &hellip;]{.blue}
>
> 4. Let `sndr` and `env` be subexpressions such that `Sndr` is `decltype((sndr))`{.cpp}
>    and `Env` is `decltype((env))`{.cpp}. If ```@_`sender-for`_@<Sndr, stopped_as_optional_t>```{.cpp}
>    is `false` then the expression
>    ```stopped_as_optional.@[`transform_sender`]{.rm}[_`transform-sender`_]{.add}@(sndr, env)```{.cpp}
>    is ill-formed; otherwise,
>    if ```sender_in<@_`child-type`_@<Sndr>, @_`FWD-ENV-T`_@(Env)>```{.cpp} is `false`, the expression
>    ```stopped_as_optional.@[`transform_sender`]{.rm}[_`transform-sender`_]{.add}@(sndr, env)```{.cpp}
>    is equivalent to ```@_`not-a-sender`_@()```{.cpp}; otherwise, it is equivalent to:
>
>    > ```cpp
>    > auto&& [_, _, child] = sndr;
>    > using V = @_`single-sender-value-type`_@<@_`child-type`_@<Sndr>, @_`FWD-ENV-T`_@(Env)>;
>    > return let_stopped(
>    >   then(std::forward_like<Sndr>(child),
>    >         []<class... Ts>(Ts&&... ts) noexcept(is_nothrow_constructible_v<V, Ts...>) {
>    >            return optional<V>(in_place, std::forward<Ts>(ts)...);
>    >         }),
>    >   []() noexcept { return just(optional<V>()); });
>    > ```
>

[Change [exec.stopped.err]{.sref} paragraphs 2 and 3 as follows:]{.ednote}

> 2. The name `stopped_as_error` denotes a pipeable sender adaptor object. For some
>    subexpressions `sndr` and `err`, let `Sndr` be `decltype((sndr))`{.cpp} and let `Err`
>    be `decltype((err))`. If the type `Sndr` does not satisfy `sender` or if the type
>    `Err` does not satisfy _`movable-value`_, `stopped_as_error(sndr, err)` is
>    ill-formed. Otherwise, the expression `stopped_as_error(sndr)` is
>    expression-equivalent to[:]{.rm}
>    [```@_`make-sender`_@(stopped_as_error, err, sndr)```{.cpp}.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > transform_sender(@_`get-domain-early`_@(sndr), @_`make-sender`_@(stopped_as_error, err, sndr))
>    > ```
>
>    except that `sndr` is only evaluated once.
>
>    :::
>
> 2. Let `sndr` and `env` be subexpressions such that `Sndr` is `decltype((sndr))`{.cpp}
>    and `Env` is `decltype((env))`{.cpp}. If ```@_`sender-for`_@<Sndr, stopped_as_error_t>```{.cpp}
>    is `false` then the expression
>    ```stopped_as_error.@[`transform_sender`]{.rm}[_`transform-sender`_]{.add}@(sndr, env)```{.cpp}
>    is ill-formed; otherwise, it is equivalent to:
>
>    > ```cpp
>    > auto&& [_, err, child] = sndr;
>    > using E = decltype(auto(err));
>    > return let_stopped(
>    >   std::forward_like<Sndr>(child),
>    >   [err = std::forward_like<Sndr>(err)]() noexcept(is_nothrow_move_constructible_v<E>) {
>    >     return just_error(std::move(err));
>    >   });
>    > ```

[Change [exec.associate]{.sref} paragraph 10 as follows:]{.ednote}

> 10. The name `associate` denotes a pipeable sender adaptor object. For subexpressions `sndr`
>     and `token`:
>
>     - [10.1]{.pnum} If `decltype((sndr))`{.cpp} does not satisfy `sender`, or
>       `remove_cvref_t<decltype((token))>`{.cpp} does not satisfy `scope_token`, then
>       `associate(sndr, token)` is ill-formed.
>
>     - [10.2]{.pnum} Otherwise, the expression `associate(sndr, token)` is
>       expression-equivalent to[:]{.rm}
>       [```@_`make-sender`_@(associate, @_`associate-data`_@(token, sndr))```{.cpp}.]{.add}
>
>       ::: rm
>
>       > ```cpp
>       > transform_sender(@_`get-domain-early`_@(sndr),
>       >                  @_`make-sender`_@(associate, @_`associate-data`_@(token, sndr)))
>       > ```
>
>       except that `sndr` is evaluated only once.
>
>       :::

[Change [exec.sync.wait]{.sref} paragraphs 4 and 9 as follows:]{.ednote}

> 4. The name `this_thread​::​sync_wait`{.cpp} denotes a customization point object. For a
>    subexpression `sndr`, let `Sndr` be `decltype((sndr))`{.cpp}. The expression
>    `this_thread​::​sync_wait(sndr)`{.cpp} is expression-equivalent to [the
>    following, except that `sndr` is evaluated only once:]{.rm}
>    [```sync_wait.@_`apply`_@(sndr)```{.cpp}, where _`apply`_ is the exposition-only
>    member function specified below.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > apply_sender(@_`get-domain-early`_@(sndr), sync_wait, sndr)
>    > ```
>
>    :::
>
>    _Mandates_:
>
>    - [4.1]{.pnum} ```sender_in<Sndr, @_`sync-wait-env`_@>```{.cpp} is true.
>
>    - [4.2]{.pnum} The type ```@_`sync-wait-result-type`_@<Sndr>```{.cpp} is well-formed.
>
>    ::: rm
>
>    - [4.3]{.pnum} ```same_as<decltype(@_`e`_@), @_`sync-wait-result-type`_@<Sndr>>```{.cpp}
>      is `true`, where _`e`_ is the `apply_sender` expression i>
>    :::
>
> [&hellip; as before &hellip;]{.blue}
>
> 9. For a subexpression `sndr`, let `Sndr` be `decltype((sndr))`{.cpp}. If
>    ```sender_to<Sndr, @_`sync-wait-receiver`_@<Sndr>>```{.cpp} is `false`{.cpp}, the
>    expression ```sync_wait.@[`apply_sender`]{.rm}[_`apply`_]{.add}@(sndr)```{.cpp} is
>    ill-formed; otherwise, it is equivalent to:
>
>    ```cpp
>    @_`sync-wait-state`_@<Sndr> state;
>    auto op = connect(sndr, @_`sync-wait-receiver`_@<Sndr>{&state});
>    start(op);
>
>    state.loop.run();
>    if (state.error) {
>      rethrow_exception(std::move(state.error));
>    }
>    return std::move(state.result);
>    ```

[Change _Note 1_ in [exec.sync.wait]{.sref} paragraph 10.1 as follows:]{.ednote}

> [_Note 1_: The [default]{.rm} implementation of `sync_wait` achieves forward progress
> guarantee delegation by providing a `run_loop` scheduler via the
> `get_delegation_scheduler` query on the _`sync-wait-receiver`_'s environment. The
> `run_loop` is driven by the current thread of execution. — _end note_]


[Change [exec.sync.wait.var]{.sref} paragraphs 1 and 2 as follows:]{.ednote}

> 1. The name `this_thread​::​sync_wait_with_variant` denotes a customization point
>    object. For a subexpression `sndr`, let `Sndr` be
>    `decltype(into_variant(sndr))`{.cpp}. The expression
>    `this_thread​::​sync_wait_with_variant(sndr)`{.sref} is expression-equivalent to [the
>    following, except `sndr` is evaluated only once:]{.rm}
>    [```sync_wait_with_variant.@_`apply`_@(sndr)```{.cpp}, where _`apply`_ is the
>    exposition-only member function specified below.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > apply_sender(get-domain-early(sndr), sync_wait_with_variant, sndr)
>    > ```
>
>    :::
>
>    _Mandates_:
>
>    - [1.1]{.pnum} ```sender_in<Sndr, @_`sync-wait-env`_@>```{.cpp} is `true`{.cpp}.
>
>    - [1.2]{.pnum} The type ```@_`sync-wait-with-variant-result-type`_@<Sndr>```{.cpp} is well-formed.
>
>    ::: rm
>
>    - [1.3]{.pnum} ```same_as<decltype(@_`e`_@), @_`sync-wait-with-variant-result-type`_@<Sndr>>```{.cpp}
>      is `true`{.cpp}, where _`e`_ is the `apply_sender` expression i>
>    :::
>
> 2. The expression ```sync_wait_with_variant.@[`apply_sender`]{.rm}[_`apply`_]{.add}@(sndr)```{.cpp}
>    is equivalent to:
>
>    > ```cpp
>    > using result_type = @_`sync-wait-with-variant-result-type`_@<Sndr>;
>    > if (auto opt_value = sync_wait(into_variant(sndr))) {
>    >   return result_type(std::move(get<0>(*opt_value)));
>    > }
>    > return result_type(nullopt);
>    > ```

[Change _Note 1_ in [exec.sync.wait]{.sref} paragraph 10.1 as follows:]{.ednote}

> [_Note 1_: The [default]{.rm} implementation of `sync_wait_with_variant` achieves
> forward progress guarantee delegation ([intro.progress]{.sref}) by relying on the
> forward progress guarantee delegation provided by `sync_wait`. — _end note_]


[Change [exec.env]{.sref} as follows:]{.ednote}

> > ```cpp
> > namespace std::execution {
> >   template<@_`queryable`_@... Envs>
> >   struct env {
> >     @Envs~0~ envs~0~@;               // exposition only
> >     @Envs~1~ envs~1~@;               // exposition only
> >       ⋮
> >     @Envs~*n*-1~ envs~*n*-1~@;            // exposition only
> >
> >     template<class QueryTag@[`, class... Args`]{.add}@>
> >       constexpr decltype(auto) query(QueryTag q@[`, Args&&... args`]{.add}@) const noexcept(@_`see below`_@);
> >   };
> >
> >   template<class... Envs>
> >     env(Envs...) -> env<unwrap_reference_t<Envs>...>;
> > }
> > ```
>
> 1. The class template `env` is used to construct a queryable object from several
>    queryable objects. Query invocations on the resulting object are resolved by
>    attempting to query each subobject in lexical order.
>
> > [&hellip; as before &hellip;]{.blue}
>
> > ```cpp
> > template<class QueryTag@[`, class... Args`]{.add}@>
> > constexpr decltype(auto) query(QueryTag q@[`, Args&&... args`]{.add}@) const noexcept(@_`see below`_@);
> > ```
>
> 5. Let _`has-query`_ be the following exposition-only concept:
>
>    > ```cpp
>    > template<class Env, class QueryTag@[`, class... Args`]{.add}@>
>    >   concept @_`has-query`_@ =                   // exposition only
>    >     requires (const Env& env@[`, Args&&... args`]{.add}@) {
>    >       env.query(QueryTag()@[`, std::forward<Args>(args)...`]{.add}@);
>    >     };
>    > ```
>
> 6. Let _`fe`_ be the first element of ```@_envs_~0~@, @_envs_~1~@, @&hellip;@ @_envs_~_n_-1~@```{.cpp}
>    such that the expression ```@_`fe`_@.query(q@[`, std::forward<Args>(args)...`]{.add}@)```{.cpp}
>    is well-formed.
>
> 7. _Constraints_: ```(@_`has-query`_@<Envs, QueryTag@[`, Args...`]{.add}@> || ...)```{.cpp} is `true`{.cpp}.
>
> 8. _Effects_: Equivalent to: ```return @_`fe`_@.query(q@[`, std::forward<Args>(args)...`]{.add}@);```{.cpp}
>
> 9. _Remarks_: The expression in the `noexcept`{.cpp} clause is equivalent to
>    ```noexcept(@_`fe`_@.query(q@[`, std::forward<Args>(args)...`]{.add}@))```{.cpp}.


[In [exec.run.loop.types]{.sref}, add a new paragraph after paragraph 4 as follows:]{.ednote}

> 4. Let _`sch`_ be an expression of type _`run-loop-scheduler`_. The expression
>    `schedule(sch)`{.cpp} has type _`run-loop-sender`_ and is not potentially-throwing if
>    _`sch`_ is not potentially-throwing.
> 
> ::: add
> 
> 5. For type _`set-tag`_ other than `set_error_t`, the expression
>    ```get_completion_scheduler<@_`set-tag`_@>(get_env(schedule(@_`sch`_@))) == @_`sch`_@```{.cpp}
>    evaluates to `true`.
> 
> :::


[Change [exec.affine.on]{.sref} paragraph 3 as follows:]{.ednote}

> 3. Otherwise, the expression `affine_on(sndr, sch)`{.cpp} is expression-equivalent
>    to[:]{.rm} [```@_`make-sender`_@(affine_on, sch, sndr)```{.cpp}.]{.add}
>
>    ::: rm
>
>    > ```cpp
>    > transform_sender(@_`get-domain-early`_@(sndr), @_`make-sender`_@(affine_on, sch, sndr))
>    > ```
>
>    except that `sndr` is evaluated only once.
>
>    :::


[Change paragraph 3 of [exec.inline.scheduler]{.sref} as follows:]{.ednote}

> 3. Let sndr be an expression of type _`inline-sender`_, let `rcvr` be an expression such
>    that `receiver_of<decltype((rcvr)), CS>`{.cpp} is `true`{.cpp} where `CS` is
>    `completion_signatures<set_value_t()>`{.cpp}, then[:]{.rm} [Move the text of (3.1)
>    below into this paragraph.]{.ednote}
> 
>    [3.1]{.pnum} the expression `connect(sndr, rcvr)` has type
>    ```@_`inline-state`_@<remove_cvref_t<decltype((rcvr))>>```{.cpp} and is
>    potentially-throwing if and only if `((void)sndr, auto(rcvr))`{.cpp} is
>    potentially-throwing[, and]{.rm}[.]{.add}
> 
>    ::: rm
> 
>    [3.2]{.pnum} the expression
>    `get_completion_scheduler<set_value_t>(get_env(sndr))`{.cpp} has type​
>    `inline_scheduler` and is potentially-throwing if and only if `get_env(sndr)`{.cpp} is
>    potentially-throwing.
> 
>    :::

[Change [exec.task.scheduler]{.sref} as follows:]{.ednote}

> ```cpp
> namespace std::execution {
>   class task_scheduler {
>     @@[```class @_`ts-sender`_@;                    @_// exposition only_@```]{.rm}@@
>
>     @@[```template<receiver R>```]{.rm}@@
>       @@[```class state;                      @_// exposition only_@```]{.rm}@@
>
>     @@[```template<class Sch>```]{.add}@@
>       @@[```class @_`backend-for`_@;              @_// exposition only_@```]{.add}@@
>   public:
>     using scheduler_concept = scheduler_t;
>
>     template<class Sch, class Allocator = allocator<void>>
>       requires (!same_as<task_scheduler, remove_cvref_t<Sch>>) && scheduler<Sch>
>     explicit task_scheduler(Sch&& sch, Allocator alloc = {});
>
>     @[_`ts-sender`_]{.rm}[_`see below`_]{.add}@ schedule();
>
>     @@[```template <class Sndr, class Env>     @_// exposition only_@```]{.add}@@
>       @@[```@_`see below`_@ @_`bulk-transform`_@(Sndr&& sndr, const Env& env);```]{.add}@@
>
>     friend bool operator==(const task_scheduler& lhs, const task_scheduler& rhs) noexcept;
>
>     template<class Sch>
>       requires (!same_as<task_scheduler, Sch>) && scheduler<Sch>
>     friend bool operator==(const task_scheduler& lhs, const Sch& rhs) noexcept;
>
>   private:
>     shared_ptr<@[`void`]{.rm}[`parallel_scheduler_backend`]{.add}@> @_`sch_`_@; // exposition only
>                                                      @[_`// see [exec.sysctxrepl.psb]`_]{.add}@
>   };
> }
> ```
>
> 1. `task_scheduler` is a class that models `scheduler` ([exec.sched]{.sref}). Given an object
>    `s` of type `task_scheduler`, let ```@_`SCHED`_@(s)```{.cpp} be [the _`sched_`_ member
>    of]{.add} the object owned by ``s.@_`sch_`_@``.
>
> ::: add
>
> 2. For an lvalue `r` of type derived from `receiver_proxy`, let ```@_`WRAP-RCVR`_@(r)```{.cpp}
>    be an object of a type that models `receiver` and whose
>    completion handlers result in invoking the corresponding completion handlers of `r`.
>
> > ```cpp
> > template<class Sch>
> > struct @_`backend-for`_@ : parallel_scheduler_backend {           @_`// exposition only`_@
> >   explicit @_`backend-for`_@(Sch sch) : sched_(std::move(sch)) {}
> >
> >   void schedule(receiver_proxy& r, span<byte> s) noexcept override;
> >   void schedule_bulk_chunked(size_t shape, bulk_item_receiver_proxy& r,
> >                              span<byte> s) noexcept override;
> >   void schedule_bulk_unchunked(size_t shape, bulk_item_receiver_proxy& r,
> >                                span<byte> s) noexcept override;
> >
> >   Sch @_`sched_`_@; @_`// exposition only`_@
> > };
> > ```
>
> 3. Let `sndr` be a sender whose only value completion signature is
>    `set_value_t()` and for which the expression
>    ```get_completion_scheduler<set_value_t>(get_env(sndr)) == @_`sched_`_@```{.cpp} is
>    `true`.
>
> > ```cpp
> > void schedule(receiver_proxy& r, span<byte> s) noexcept override;
> > ```
>
> 4. _Effects_: Constructs an operation state `os` with
>    ```connect(schedule(@_`sched_`_@), @_`WRAP-RCVR`_@(r))```{.cpp} and calls `start(os)`.
>
> > ```cpp
> > void schedule_bulk_chunked(size_t shape, bulk_item_receiver_proxy& r,
> >                            span<byte> s) noexcept override;
> > ```
>
> 5. _Effects_: Let `chunk_size` be an integer less than or equal to `shape`, let
>    `num_chunks` be `(shape + chunk_size - 1) / chunk_size`, and let `fn` be a function
>    object such that for an integer `i`, `fn(i)` calls `r.execute(i * chunk_size, m)`,
>    where `m` is the lesser of `(i + 1) * chunk_size` and `shape`. Constructs an
>    operation state `os` as if with
>    ```connect(bulk(sndr, par, num_chunks, fn), @_`WRAP-RCVR`_@(r))```{.cpp} and calls
>    `start(os)`.
>
> > ```cpp
> > void schedule_bulk_unchunked(size_t shape, bulk_item_receiver_proxy& r,
> >                              span<byte> s) noexcept override;
> > ```
>
> 6. _Effects_: Let `fn` be a function object such that for an integer `i`, `fn(i)` is
>    equivalent to `r.execute(i, i + 1)`. Constructs an operation state `os` as if with
>    ```connect(bulk(sndr, par, shape, fn), @_`WRAP-RCVR`_@(r))```{.cpp} and calls
>    `start(os)`.
>
> :::
>
> > ```cpp
> > template<class Sch, class Allocator = allocator<void>>
> >   requires(!same_as<task_scheduler, remove_cvref_t<Sch>>) && scheduler<Sch>
> > explicit task_scheduler(Sch&& sch, Allocator alloc = {});
> > ```
>
> 2. _Effects_: Initialize _`sch_`_ with
>    ```allocate_shared<@[_`backend-for`_<]{.add}@remove_cvref_t<Sch>@[`>`]{.add}@>(alloc,​ std​::​forward<Sch>​(sch))```{.cpp}.
>
> [Paragraphs 3-7 are kept unmodified. Remove paragraphs 8-12 and add the following
> paragraphs:]{.ednote}
>
> ::: add
>
> ```cpp
> @_`see below`_@ schedule();
> ```
>
> 8. _Returns_: a prvalue `sndr` whose type `Sndr` models `sender` such that:
>
>    - [8.1]{.pnum} `get_completion_scheduler<set_value_t>(get_env(sndr))`{.cpp} is equal
>      to `*this`{.cpp}.
>
>    - [8.2]{.pnum} If a receiver `rcvr` is connected to `sndr` and the resulting
>      operation state is started, calls ``@_`sch_`_@->schedule(r, s)``, where
>
>      - [8.2.1]{.pnum} `r` is a proxy for `rcvr` with base
>        `system_context_replaceability​::​receiver_proxy`{.cpp}
>        ([exec.par.scheduler]{.sref}) and
>
>      - [8.2.2]{.pnum} `s` is a preallocated backend storage for `r`.
>
> ```cpp
> template <class BulkSndr, class Env>     @_// exposition only_@
>   @_`see below`_@ @_`bulk-transform`_@(BulkSndr&& bulk_sndr, const Env& env);
> ```
>
> 9. _Constraints_: `sender_in<BulkSndr, Env>` is `true` and either
>    ```@_`sender-for`_@<BulkSndr, bulk_chunked_t>```{.cpp} or
>    ```@_`sender-for`_@<BulkSndr, bulk_unchunked_t>```{.cpp} is `true`.
>
> 10. _Returns_: a prvalue `sndr` whose type models `sender` such that:
>
>     - [10.1]{.pnum} `get_completion_scheduler<set_value_t>(get_env(sndr))`{.cpp} is
>       equal to `*this`{.cpp}.
>
>     - [10.2]{.pnum} `bulk_sndr` is connected to an unspecified receiver if a receiver
>       `rcvr` is connected to `sndr`. If the resulting operation state is started,
>
>       - [10.2.1]{.pnum} If `bulk_sndr` completes with values `vals`, let `args` be a
>         pack of lvalue subexpressions designating objects decay-copied from `vals`. Then
>
>         - [10.2.1.1]{.pnum} If `bulk_sndr` is the result of calling `bulk_chunked(child,
>           policy, shape, f)`, ```@_`sch_`_@->schedule_bulk_chunked(shape, r, s)```{.cpp} is
>           called where `r` is a bulk chunked proxy for `rcvr` with callable `f` and
>           arguments `args`, and `s` is a preallocated backend storage for `r`.
>
>         - [10.2.1.2]{.pnum} Otherwise, `bulk_sndr` is the result of calling
>           `bulk_unchunked(child, policy, shape, f)`. Calls
>           ```@_`sch_`_@->schedule_bulk_unchunked(shape, r, s)```{.cpp} where `r` is a bulk
>           unchunked proxy for `rcvr` with callable `f` and arguments `args`, and `s` is
>           a preallocated backend storage for `r`.
>
>       - [10.2.2]{.pnum} All other completion operations are forwarded unchanged.
>
> :::


<a name="proposed-wording-for-parallel-scheduler"></a>

[In [exec.par.scheduler]{.sref}, add a new paragraph after paragraph 3, another before
paragraph 10, and change paragraphs 10 and 11 as follows:]{.ednote}


> 3. The expression `get_forward_progress_guarantee(sch)`{.cpp} returns
>    `forward_progress_guarantee​::​parallel`.
> 
> ::: add
> 
> [?.]{.npnum} The expression
> `get_completion_scheduler<set_value_t>(get_env(schedule(sch))) == sch`{.cpp} evaluates
> to `true`.
> 
> :::
> 
> [&hellip; as before &hellip;]{.blue}
> 
> ::: add
>
> [?.]{.npnum} Let `sch` be a subexpression of type `parallel_scheduler`. For
>     subexpressions `sndr` and `env`, if `tag_of_t<Sndr>` is neither `bulk_chunked_t` nor
>     `bulk_unchunked_t`, the expression ```sch.@_`bulk-transform`_@(sndr, env)```{.cpp}
>     is ill-formed; otherwise, let `child`, `pol`, `shape`, and `f` be subexpressions
>     equal to the arguments used to create `sndr`.
>
> :::
>
> 10. [`parallel_scheduler` provides a customized implementation of the `bulk_chunked`
>     algorithm ([exec.bulk]{.sref}). If a receiver `rcvr` is connected to the sender
>     returned by `bulk_chunked(sndr, pol, shape, f)`{.cpp}]{.rm} [When the tag type of
>     `sndr` is `bulk_chunked_t`, the expression
>     ```sch.@_`bulk-transform`_@(sndr, env)```{.cpp} returns a sender such
>     that if it is connected to a receiver `rcvr`]{.add} and the resulting operation
>     state is started, then:
>
>     - [10.1]{.pnum} If [`sndr`]{.rm}[`child`]{.add} completes with values `vals`, let
>       `args` be a pack of lvalue subexpressions designating `vals`, then
>       `b.schedule_bulk_chunked(shape, r, s)`{.cpp} is called, where
>
>       - [10.1.1]{.pnum} `r` is a bulk chunked proxy for `rcvr` with callable `f` and
>         arguments `args` and
>
>       - [10.1.2]{.pnum} `s` is a preallocated backend storage for `r`.
>
>     - [10.2]{.pnum} All other completion operations are forwarded unchanged.
>
>     [Customizing the behavior of `bulk_chunked` affects the [default]{.rm}
>     implementation of `bulk`.]{.note}
>
> 11. [`parallel_scheduler` provides a customized implementation of the `bulk_unchunked`
>     algorithm ([exec.bulk]{.sref}). If a receiver `rcvr` is connected to the sender
>     returned by `bulk_unchunked(sndr, pol, shape, f)`{.cpp}]{.rm} [When the tag type of
>     `sndr` is `bulk_unchunked_t`, the expression ```sch.@_`bulk-transform`_@(sndr, env)```{.cpp}
>     returns a sender such that if it is connected to a receiver `rcvr`]{.add} and the
>     resulting operation state is started, then:
>
>     - [11.1]{.pnum} If [`sndr`]{.rm}[`child`]{.add} completes with values `vals`, let
>       `args` be a pack of lvalue subexpressions designating `vals`, then
>       `b.schedule_bulk_unchunked(shape, r, s)`{.cpp} is called, where
>
>       - [11.1.1]{.pnum} `r` is a bulk unchunked proxy for `rcvr` with callable `f` and
>         arguments `args` and
>
>       - [11.1.2]{.pnum} `s` is a preallocated backend storage for `r`.
>
>     - [11.2]{.pnum} All other completion operations are forwarded unchanged.



# Appendix A: The planned fix

Our willingness to remove algorithm customization depends on our confidence that we can
add it back later without breaking code. Section [](#restoring-algorithm-customization-in-c29)
talks about how we would go about this. This appendix fleshies out some of the details.

## Mission statement

A sender expression represents a task graph, the nodes of which are asynchronous
operations. Every async operation is started on some execution context, the _starting
context_, and completes on another execution context, the _completing context_. The two
might be the same, but that's irrelevant.

::: callout

[Note]{.callout-header} [This is a simplification. Some senders like
`when_all` can complete on one of several contexts. We solve that problem with domains as
described below.]{.callout-content}

:::

Imagine we assign each execution resource a color. The mission then is to paint every node
in the task graph with the colors of its starting and completing contexts. Once we know
where each operation will start and complete, we can use that information to pick the
right algorithm implementation.

In regards to customization, each color can be thought to represent not an individual
execution resource, but rather a set of algorithm implementations. Two different execution
resources might use the same set of algorithm implementations, so they would have the same
"color". In fact, most execution resources will use the default set of algorithm
implementations, in which case they all have the same color.

That's not always the case though. A thread pool would not want to use the default
implementation of `bulk` for example -- that would be serial. The thread pool would have
a different color corresponding to its set of preferred algorithm implementations.

In `std::execution` today, this notion of color is called a "domain". A domain is a tag
type that is used to select a set of algorithm implementations. Schedulers, which are
stand-ins for execution resources, advertize their domain with the `get_domain` query.

## Achieving the mission

Completing the mission requires two things:

1. Identifying the starting and completing domain of every operation in the task graph,
   and

2. Using that information to select the preferred implementation for the algorithm
   that operation represents.

Let's take these two separately.

### Coloring the graph

#### Early Customization

So-called "early" customization, which determines the return type of `then(sndr, fn)` for
example, is predicated on the fact that senders know the domain on which they will complete.
As discussed above, that's false. Many senders only know where they will complete once they
know where they will start, which isn't known until the sender is connected to a receiver.

So early customization is irreparably broken. There is no plan to add it back.

#### Late Customization

That leaves late customization, which is performed by the `connect` customization point.
The receiver, which is an extension of caller, knows where the operation will start.
_If the sender is given this information -- that is, if the sender is told where it will
start -- it can accurately report where it will complete._ This is the key insight.

When `connect` queries a sender's attributes for its domain, it should pass the
receiver's environment. That way a sender has all the information available when
computing its completion domain.

#### `get_completion_domain`

It is sometimes the case that a sender's value and error completions can happen on
different domains. For example, imagine trying to schedule work on a GPU. If it succeeds,
you are in the GPU domain, and Bob's your uncle. If scheduling fails, however, the error
cannot be reported on the GPU because we failed to make it there!

So asking a sender for a singular completion domain is not flexible enough. We have three
separate queries for a sender's completion scheduler:
`get_completion_scheduler<set_[value|error|stopped]_t>`. Similarly, we should have three
separate queries for a sender's completion domain:
`get_completion_domain<set_[value|error|stopped]_t>`.

::: callout

[Note]{.callout-header} [If we have the `get_completion_scheduler` queries, why do we need
`get_completion_domain`? We can ask the completion scheduler for its domain, right? The
answer is that a sender like `when_all(s1, s2)`{.cpp} doesn't know what scheduler it will
complete on. It completes on the context of whichever sender, `s1` or `s2`, finishes last.
But if `s1` and `s2` have the same completion _domain_, it doesn't matter that we do not
know the completion scheduler. The _domain_ determines the preferred set of algorithm
implementations. Hence we need separate queries for the completion domain. (Additionally,
`when_all` must require that all of its child senders share a common
domain.)]{.callout-context}

:::

The addition of the completion domain queries creates a nice symmetry as shown in the
table below (with additions in green):

|                     | Receiver        |  Sender   |
|---------------------|-----------------|-----------|
| Query for scheduler | `get_scheduler` | `get_completion_scheduler<set_value_t>`<br/>`get_completion_scheduler<set_error_t>`<br/>`get_completion_scheduler<set_stopped_t>`  |
| Query for domain    | `get_domain`    | [`get_completion_domain<set_value_t>`<br/>`get_completion_domain<set_error_t>`<br/>`get_completion_domain<set_stopped_t>`]{.green} |

For a sender `sndr` and an environment `env`, we can get the sender's completion domain
as follows:

> ```cpp
> auto completion_domain = get_completion_domain<set_value_t>(get_env(sndr), env);
> ```

A sender like `just()` would implement this query as follows:

> ```cpp
> template <class... Values>
> class just_sender {
> private:
>   struct attrs {
>     template <class Env>
>     auto query(get_completion_domain_t<set_value_t>, const Env& env) const noexcept {
>       // just(...) completes where it starts. the domain of the environment is where
>       // the sender will start, so return that.
>       return get_domain(env);
>     }
>     //...
>   };
>
> public:
>   attrs get_env() const noexcept {
>     return attrs{};
>   }
>
>   //...
> };
> ```

::: callout

[Note]{.callout-header} [A query that accepts an additional argument is novel in
`std::execution`, but the query system was designed to support this usage. See
[exec.queryable.concept]{.sref}.]{.callout-content}

:::


### Dispatching in `connect`

With the addition of the `get_completion_domain<...>` queries that can accept the
receiver's environment, `connect` can now "paint" the operation with its starting and
completing colors, aka domains. When passed arguments `sndr` and `rcvr`, the starting
domain is:

> ```c++
> // Get the operation's starting domain:
> auto starting_domain = get_domain(get_env(rcvr));
> ```

To get the completion domain (when the operation completes successfully):

> ```c++
> // Get the operation's completion domain for the value channel:
> auto completion_domain = get_completion_domain<set_value_t>(get_env(sndr), get_env(rcvr));
> ```

Now `connect` has all the information it needs to select the correct algorithm
implementation. Great!

But this presents the `connect` function with a dilemna: how does it use _two_ domains to
pick _one_ algorithm implementation?

Consider that the starting domain might want a say in how `start` works, and the
completing domain might want a say in how `set_value` works. So should we let the starting
domain customize `start` and the completing domain customize `set_value`?

No. `start` and `set_value` are bookends around an async operation; they must match. Often
`set_value` needs state that is set up in `start`. Customizing the two independently is
madness.

#### Solving the double-dispatch problem

::: callout

[Note]{.callout-header}[The following is more speculative than what has been described so
far.]{.callout-content}

:::

A possible solution I have been exploring is to bring back sender transforms. Each domain
can apply its transform in turn. I do not yet have reason to believe the order matters,
but it is important that when asked to transform a sender, a domain knows whether it is
the "starting" domain or the "completing" domain.

Here is how a domain might customize `bulk` when it is the completing domain:

> ```cpp
> struct thread_pool_domain {
>   template <@_`sender-for`_@<bulk_t> Sndr, class Env>
>   auto transform_sender(set_value_t, Sndr&& sndr, const Env& env) const {
>     //...
>   }
> };
> ```

Since it has `set_value_t` as its first argument, this transform is only applied when
`thread_pool_domain` is an operation's completion domain. Had the first argument been
`start_t`, the transform would only be used when `thread_pool_domain` is a starting
domain.

**`transform_sender`**

In this reimagined customization design, the `connect` CPO does a few things:

1. Determines the starting and completing domains,

2. Applies the completing domain's transform (if any),

3. Applies the starting domain's transform (if any) to the resulting sender,

4. Connnects the twice-transformed sender to the receiver.

The first three steps are doing something different than connecting a sender and receiver,
so it makes sense to factor them out into their own utility. I call it `transform_sender`
here, but it does not need to be normative since only `connect` will call it.

The new `transform_sender` looks like this:

> ```cpp
> template <class Domain, class Tag, class Sndr, class Env>
> concept @_`has-sender-transform-for`_@ = requires (Sndr(*make_sndr)(), const Env env) {
>   Domain().transform_sender(Tag(), make_sndr(), env);
> }
>
> template <class Domain, class Tag>
> constexpr auto @_`transform-sender-recurse`_@ = @_`overload-set`_@{
>   []<class Self, class Sndr, class Env>(this Self self, Sndr&& sndr, const Env& env)
>     -> decltype(auto) requires @_`has-sender-transform-for`_@<Domain, Tag, Sndr, Env> {
>     return self(Domain().transform_sender(Tag(), std::forward<Sndr>(sndr), env));
>   },
>   []<class Sndr, class Env>(Sndr&& sndr, const _Env&) -> Sndr {
>     return std::forward<Sndr>(sndr);
>   }
> };
>
> template <class Sndr, class Env>
> auto transform_sender(Sndr&& sndr, const Env& env) {
>   auto starting_domain      = get_domain(env);
>   auto completing_domain    = get_completion_domain<set_value_t>(get_env(sndr), env);
>
>   auto starting_transform   = @_`transform-sender-recurse`_@<decltype(starting_domain), start_t>;
>   auto completing_transform = @_`transform-sender-recurse`_@<decltype(completing_domain), set_value_t>;
>
>   return starting_transform(completing_transform(std::forward<Sndr>(sndr), env), env);
> }
> ```

With this definition of `transform_sender`, `connect(sndr, rcvr)` is equivalent to
`transform_sender(sndr, get_env(rcvr)).connect(rcvr)`.


#### Revisiting the problematic example

Let's see how this new approach addresses the problems noted in the motivating example
[above](#the-problem-with-p3718). The troublesome code is:

> ```cpp
> namespace ex = std::execution;
> auto sndr = ex::starts_on(gpu, ex::just()) | ex::then(fn);
> std::this_thread::sync_wait(std::move(sndr));
> ```

[](#the-problem-with-p3718) describes how the current design and the "fixed" one proposed
in [@P3718R0] go off the rails while determining the domain in which the function `fn`
will execute, causing it to use a CPU implementation instead of a GPU one.

In the new design, when the `then` sender is being connected to `sync_wait`'s receiver,
the starting domain will still be the `default_domain`, but when asking the sender where
it will complete, the answer will be different. Let's see how:

* When asked for its completion domain, the `then` sender will ask the `starts_on` sender
  where it will complete, as if by:

  > ```cpp
  > auto&& @_`tmp1`_@ = ex::starts_on(gpu, ex::just());
  > auto @_`dom1`_@ = ex::get_completion_domain<ex::set_value_t>(ex::get_env(@_`tmp1`_@), ex::get_env(rcvr));
  > ```

* In turn, the `starts_on` sender asks the `just()` sender where it will complete,
  _telling it where it will start_. (This is the new bit.) It looks like:

  > ```cpp
  > auto&& @_`tmp2`_@ = ex::just();
  > // ask for the gpu scheduler's domain:
  > auto @_`gpu-dom`_@ = ex::get_completion_domain<ex::set_value_t>(gpu);
  > // construct an env that reflects the fact that @_`tmp2`_@ will be started on the gpu:
  > auto @_`env2`_@ = ex::env{ex::prop{ex::get_scheduler, gpu}, 
  >                     ex::prop{ex::get_domain, @_`gpu-dom`_@},
  >                     ex::get_env(rcvr)};
  > // pass the new env when asking `just()` for its completion domain:
  > auto @_`dom2`_@ = ex::get_completion_domain<ex::set_value_t>(ex::get_env(@_`tmp2`_@), @_`env2`_@);
  > ```

* The `just()`{.cpp} sender, when asked where it will complete, will respond with the domain
  on which it is started. That information is provided by the _`env2`_ environment passed to the
  query: ```get_domain(@_`env2`_@)```{.cpp}. That will return _`gpu-dom`_.

* Having correctly determined that the `then` sender will start on the default domain
  and complete on the GPU domain, `connect` can select the right implementation for the
  `then` algorithm. It does that by calling:

  > ```cpp
  > return ex::transform_sender(sndr, ex::get_env(rcvr)).connect(rcvr);
  > ```

  The `transform_sender` call will execute the following (simplified):

  > ```cpp
  > ex::default_domain().transform_sender(ex::start,
  >                                       @_`gpu-dom`_@.transform_sender(ex::set_value, sndr, ex::get_env(rcvr)),
  >                                       ex::get_env(rcvr))
  > ```

  The `default_domain` does not apply any transformation to `then` senders, so this expression
  reduces to:

  > ```cpp
  > @_`gpu-dom`_@.transform_sender(ex::set_value, sndr, ex::get_env(rcvr))
  > ```

  So, in the new customization scheme, the GPU domain gets a crack at transforming the
  `then` sender before it is connected to a receiver, as it should.

